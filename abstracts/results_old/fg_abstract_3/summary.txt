best_feature_count = 20943
best_feature_ratio = 1.0%

#
# TEST SET
#
accuracy score: 0.8713798977853492

classification report:
              precision    recall  f1-score   support

          cs       0.93      0.94      0.94      1060
        eess       0.96      0.74      0.84        90
        math       0.91      0.96      0.94      1371
     physics       0.95      0.96      0.96      1590
       q-bio       0.96      0.80      0.87        90
       q-fin       0.90      0.73      0.81        37
        stat       0.89      0.90      0.89       327

   micro avg       0.93      0.94      0.94      4565
   macro avg       0.93      0.86      0.89      4565
weighted avg       0.93      0.94      0.94      4565
 samples avg       0.92      0.94      0.92      4565


classifier details:
best_params = {'classifier': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',
          tol=0.0001, verbose=0, warm_start=False), 'classifier__C': 100}
best_feature_count = 20943
best_feature_ratio = 1.0%

#
# TRAINING SET
#
accuracy score: 1.0

classification report:
              precision    recall  f1-score   support

          cs       1.00      1.00      1.00      2532
        eess       1.00      1.00      1.00       217
        math       1.00      1.00      1.00      3447
     physics       1.00      1.00      1.00      4525
       q-bio       1.00      1.00      1.00       208
       q-fin       1.00      1.00      1.00        83
        stat       1.00      1.00      1.00       770

   micro avg       1.00      1.00      1.00     11782
   macro avg       1.00      1.00      1.00     11782
weighted avg       1.00      1.00      1.00     11782
 samples avg       1.00      1.00      1.00     11782


classifier details:
best_params = {'classifier': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',
          tol=0.0001, verbose=0, warm_start=False), 'classifier__C': 100}
