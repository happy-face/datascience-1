,Unnamed: 0,id,title,subcategories,abstract,doi,created,updated,authors,main_categories
0,91,1408.1868,on the structure of classical realizability models of zf,"['cs.lo', 'math.lo']","the technique of ""classical realizability"" is an extension of the method of ""forcing""; it permits to extend the curry-howard correspondence between proofs and programs, to zermelo-fraenkel set theory and to build new models of zf, called ""realizability models"". the structure of these models is, in general, much more complicated than that of the particular case of ""forcing models"". we show here that the class of constructible sets of any realizability model is an elementary extension of the constructibles of the ground model (a trivial fact in the case of forcing, since these classes are identical). it follows that shoenfield absoluteness theorem applies to realizability models.",10.4230/lipics.types.2014.146,8/8/2014,,['krivine'],['cs']
1,95,1408.6923,gpgpu computing,['cs.dc'],"since the first idea of using gpu to general purpose computing, things have evolved over the years and now there are several approaches to gpu programming. gpu computing practically began with the introduction of cuda (compute unified device architecture) by nvidia and stream by amd. these are apis designed by the gpu vendors to be used together with the hardware that they provide. a new emerging standard, opencl (open computing language) tries to unify different gpu general computing api implementations and provides a framework for writing programs executed across heterogeneous platforms consisting of both cpus and gpus. opencl provides parallel computing using task-based and data-based parallelism. in this paper we will focus on the cuda parallel computing architecture and programming model introduced by nvidia. we will present the benefits of the cuda programming model. we will also compare the two main approaches, cuda and amd app (stream) and the new framwork, opencl that tries to unify the gpgpu computing models.",,8/29/2014,,"['oancea', 'andrei', 'dragoescu']",['math']
2,89,1408.0848,multilayer bootstrap networks,"['cs.lg', 'cs.ne', 'stat.ml']","multilayer bootstrap network builds a gradually narrowed multilayer nonlinear network from bottom up for unsupervised nonlinear dimensionality reduction. each layer of the network is a nonparametric density estimator. it consists of a group of k-centroids clusterings. each clustering randomly selects data points with randomly selected features as its centroids, and learns a one-hot encoder by one-nearest-neighbor optimization. geometrically, the nonparametric density estimator at each layer projects the input data space to a uniformly-distributed discrete feature space, where the similarity of two data points in the discrete feature space is measured by the number of the nearest centroids they share in common. the multilayer network gradually reduces the nonlinear variations of data from bottom up by building a vast number of hierarchical trees implicitly on the original data space. theoretically, the estimation error caused by the nonparametric density estimator is proportional to the correlation between the clusterings, both of which are reduced by the randomization steps.",,8/4/2014,3/6/2018,['zhang'],['cs']
3,74,1404.3311,generating synchronizing automata with large reset lengths,['cs.fl'],"we study synchronizing automata with the shortest reset words of relatively large length. first, we refine the frankl-pin result on the length of the shortest words of rank $m$, and the b\'eal, berlinkov, perrin, and steinberg results on the length of the shortest reset words in one-cluster automata. the obtained results are useful in computation aimed in extending the class of small automata for which the \v{c}ern\'y conjecture is verified and discovering new automata with special properties regarding synchronization.",,4/12/2014,3/28/2018,"['kisielewicz', 'szykuła']",['math']
4,18,1111248,the distance function on a computable graph,"['math.lo', 'cs.lo']","we apply the techniques of computable model theory to the distance function of a graph. this task leads us to adapt the definitions of several truth-table reducibilities so that they apply to functions as well as to sets, and we prove assorted theorems about the new reducibilities and about functions which have nonincreasing computable approximations. finally, we show that the spectrum of the distance function can consist of an arbitrary single btt-degree which is approximable from above, or of all such btt-degrees at once, or of the bt-degrees of exactly those functions approximable from above in at most n steps.",,11/10/2011,,"['calvert', 'miller', 'reimann']",['cs']
5,44,1309531,conditioning of random block subdictionaries with applications to   block-sparse recovery and regression,"['math.st', 'cs.it', 'math.it', 'stat.th']","the linear model, in which a set of observations is assumed to be given by a linear combination of columns of a matrix, has long been the mainstay of the statistics and signal processing literature. one particular challenge for inference under linear models is understanding the conditions on the dictionary under which reliable inference is possible. this challenge has attracted renewed attention in recent years since many modern inference problems deal with the ""underdetermined"" setting, in which the number of observations is much smaller than the number of columns in the dictionary. this paper makes several contributions for this setting when the set of observations is given by a linear combination of a small number of groups of columns of the dictionary, termed the ""block-sparse"" case. first, it specifies conditions on the dictionary under which most block subdictionaries are well conditioned. this result is fundamentally different from prior work on block-sparse inference because (i) it provides conditions that can be explicitly computed in polynomial time, (ii) the given conditions translate into near-optimal scaling of the number of columns of the block subdictionaries as a function of the number of observations for a large class of dictionaries, and (iii) it suggests that the spectral norm and the quadratic-mean block coherence of the dictionary (rather than the worst-case coherences) fundamentally limit the scaling of dimensions of the well-conditioned block subdictionaries. second, this paper investigates the problems of block-sparse recovery and block-sparse regression in underdetermined settings. near-optimal block-sparse recovery and regression are possible for certain dictionaries as long as the dictionary satisfies easily computable conditions and the coefficients describing the linear combination of groups of columns can be modeled through a mild statistical prior.",10.1109/tit.2015.2429632,9/20/2013,8/28/2016,"['bajwa', 'duarte', 'calderbank']",['math']
6,93,1408319,on the neighbour sum distinguishing index of planar graphs,"['cs.dm', 'math.co']","let $c$ be a proper edge colouring of a graph $g=(v,e)$ with integers $1,2,\ldots,k$. then $k\geq \delta(g)$, while by vizing's theorem, no more than $k=\delta(g)+1$ is necessary for constructing such $c$. on the course of investigating irregularities in graphs, it has been moreover conjectured that only slightly larger $k$, i.e., $k=\delta(g)+2$ enables enforcing additional strong feature of $c$, namely that it attributes distinct sums of incident colours to adjacent vertices in $g$ if only this graph has no isolated edges and is not isomorphic to $c_5$. we prove the conjecture is valid for planar graphs of sufficiently large maximum degree. in fact even stronger statement holds, as the necessary number of colours stemming from the result of vizing is proved to be sufficient for this family of graphs. specifically, our main result states that every planar graph $g$ of maximum degree at least $28$ which contains no isolated edges admits a proper edge colouring $c:e\to\{1,2,\ldots,\delta(g)+1\}$ such that $\sum_{e\ni u}c(e)\neq \sum_{e\ni v}c(e)$ for every edge $uv$ of $g$.",10.1002/jgt.22098,8/14/2014,3/5/2018,"['bonamy', 'przybyło']",['cs']
7,69,1403.0505,a search for quantum coin-flipping protocols using optimization   techniques,"['math.oc', 'cs.cr', 'quant-ph']","coin-flipping is a cryptographic task in which two physically separated, mistrustful parties wish to generate a fair coin-flip by communicating with each other. chailloux and kerenidis (2009) designed quantum protocols that guarantee coin-flips with near optimal bias. the probability of any outcome in these protocols is provably at most $1/\sqrt{2} + \delta$ for any given $\delta > 0$. however, no explicit description of these protocols is known, and the number of rounds in the protocols tends to infinity as $\delta$ goes to 0. in fact, the smallest bias achieved by known explicit protocols is $1/4$ (ambainis, 2001).   we take a computational optimization approach, based mostly on convex optimization, to the search for simple and explicit quantum strong coin-flipping protocols. we present a search algorithm to identify protocols with low bias within a natural class, protocols based on bit-commitment (nayak and shor, 2003) restricting to commitment states used by mochon (2005). an analysis of the resulting protocols via semidefinite programs (sdps) unveils a simple structure. for example, we show that the sdps reduce to second-order cone programs. we devise novel cheating strategies in the protocol by restricting the semidefinite programs and use the strategies to prune the search.   the techniques we develop enable a computational search for protocols given by a mesh over the parameter space. the protocols have up to six rounds of communication, with messages of varying dimension and include the best known explicit protocol (with bias 1/4). we conduct two kinds of search: one for protocols with bias below 0.2499, and one for protocols in the neighbourhood of protocols with bias 1/4. neither of these searches yields better bias. based on the mathematical ideas behind the search algorithm, we prove a lower bound on the bias of a class of four-round protocols.",10.1007/s10107-015-0909-y,3/3/2014,,"['nayak', 'sikora', 'tunçel']",['math']
8,94,1408.6771,flat foldings of plane graphs with prescribed angles and edge lengths,"['cs.cg', 'cs.ds']","when can a plane graph with prescribed edge lengths and prescribed angles (from among $\{0,180^\circ, 360^\circ$\}) be folded flat to lie in an infinitesimally thin line, without crossings? this problem generalizes the classic theory of single-vertex flat origami with prescribed mountain-valley assignment, which corresponds to the case of a cycle graph. we characterize such flat-foldable plane graphs by two obviously necessary but also sufficient conditions, proving a conjecture made in 2001: the angles at each vertex should sum to $360^\circ$, and every face of the graph must itself be flat foldable. this characterization leads to a linear-time algorithm for testing flat foldability of plane graphs with prescribed edge lengths and angles, and a polynomial-time algorithm for counting the number of distinct folded states.",10.20382/jocg.v9i1,8/28/2014,3/18/2018,"['abel', 'demaine', 'demaine', 'eppstein', 'lubiw', 'uehara']",['cs']
9,56,1401114,efficient random sampling of binary and unary-binary trees via holonomic   equations,"['cs.ds', 'math.co']",we present a new uniform random sampler for binary trees with $n$ internal nodes consuming $2n + \theta(\log(n)^2)$ random bits on average. this makes it quasi-optimal and out-performs the classical remy algorithm. we also present a sampler for unary-binary trees with $n$ nodes taking $\theta(n)$ random bits on average. both are the first linear-time algorithms to be optimal up to a constant.,,1/6/2014,1/7/2014,"['bacher', 'bodini', 'jacquot']",['math']
10,42,1308.1603,"a note on topology preservation in classification, and the construction   of a universal neuron grid","['cs.ne', 'cs.ai', 'nlin.ao', 'stat.ml']","it will be shown that according to theorems of k. menger, every neuron grid if identified with a curve is able to preserve the adopted qualitative structure of a data space. furthermore, if this identification is made, the neuron grid structure can always be mapped to a subset of a universal neuron grid which is constructable in three space dimensions. conclusions will be drawn for established neuron grid types as well as neural fields.",,8/7/2013,2/1/2018,['volz'],['cs']
11,85,1407.4908,integrating r and hadoop for big data analysis,['cs.dc'],"analyzing and working with big data could be very diffi cult using classical means like relational database management systems or desktop software packages for statistics and visualization. instead, big data requires large clusters with hundreds or even thousands of computing nodes. offi cial statistics is increasingly considering big data for deriving new statistics because big data sources could produce more relevant and timely statistics than traditional sources. one of the software tools successfully and wide spread used for storage and processing of big data sets on clusters of commodity hardware is hadoop. hadoop framework contains libraries, a distributed fi le-system (hdfs), a resource-management platform and implements a version of the mapreduce programming model for large scale data processing. in this paper we investigate the possibilities of integrating hadoop with r which is a popular software used for statistical computing and data visualization. we present three ways of integrating them: r with streaming, rhipe and rhadoop and we emphasize the advantages and disadvantages of each solution.",,7/18/2014,,"['oancea', 'dragoescu']",['math']
12,45,1309.5568,integrating communications and merging messaging via the extensible   messaging and presence protocol,['cs.ni'],"common problems affecting modern email usage include spam, lack of sender verification, lack of built-in security and lack of message integrity. this paper looks at how we can utilise the extensible messaging and presence protocol also known as xmpp to, in time, replace email facilities. we present several methods for initiating a transition away from smtp for email to rely upon the inherent benefits of xmpp with minimal disruption to existing networks and email infrastructure. we look at how a program might be used to open an existing pop3/imap account, scan for messages that can be sent to a xmpp network user, extract the message and then deliver it the xmpp user's client. we show that the system can be implemented and then deployed with a minimum of hassle and network disruption to demonstrate xmpp as a reliable and fast replacement for email as we know it today.",,9/22/2013,2/24/2018,['coleman'],['cs']
13,72,1403.5715,mining attribute-based access control policies from logs,"['cs.cr', 'cs.db']","attribute-based access control (abac) provides a high level of flexibility that promotes security and information sharing. abac policy mining algorithms have potential to significantly reduce the cost of migration to abac, by partially automating the development of an abac policy from information about the existing access-control policy and attribute data. this paper presents an algorithm for mining abac policies from operation logs and attribute data. to the best of our knowledge, it is the first algorithm for this problem.",,3/22/2014,2/12/2018,"['xu', 'stoller']",['math']
14,13,1101.1477,asynchronous code-division random access using convex optimization,"['cs.it', 'math.it']","many applications in cellular systems and sensor networks involve a random subset of a large number of users asynchronously reporting activity to a base station. this paper examines the problem of multiuser detection (mud) in random access channels for such applications. traditional orthogonal signaling ignores the random nature of user activity in this problem and limits the total number of users to be on the order of the number of signal space dimensions. contention-based schemes, on the other hand, suffer from delays caused by colliding transmissions and the hidden node problem. in contrast, this paper presents a novel pairing of an asynchronous non-orthogonal code-division random access scheme with a convex optimization-based mud algorithm that overcomes the issues associated with orthogonal signaling and contention-based methods. two key distinguishing features of the proposed mud algorithm are that it does not require knowledge of the delay or channel state information of every user and it has polynomial-time computational complexity. the main analytical contribution of this paper is the relationship between the performance of the proposed mud algorithm in the presence of arbitrary or random delays and two simple metrics of the set of user codewords. the study of these metrics is then focused on two specific sets of codewords, random binary codewords and specially constructed algebraic codewords, for asynchronous random access. the ensuing analysis confirms that the proposed scheme together with either of these two codeword sets significantly outperforms the orthogonal signaling-based random access in terms of the total number of users in the system.",10.1016/j.phycom.2011.09.006,1/7/2011,6/20/2011,"['applebaum', 'bajwa', 'duarte', 'calderbank']",['cs']
15,48,1310.6398,some remarks on lower bounds for queue machines (preliminary report),"['cs.cc', 'cs.fl']","we first give an improved lower bound for the deterministic online simulation of tapes or pushdown stores by queues. then we inspect some proofs in a classical work on queue machines in the area of formal languages and outline why a main argument in the proofs is incomplete. based on descriptional complexity, we show the intuition behind the argument to be correct.",,10/23/2013,3/11/2018,['petersen'],['math']
16,55,1312.6809,the micro dynamics of collective violence,"['physics.soc-ph', 'cs.si']","collective violence in direct confrontations between two opposing groups happens in short bursts wherein small subgroups briefly attack small numbers of opponents, while the others form a non-fighting audience. the mechanism is fighters' synchronization of intentionalities during preliminary interactions, by which they feel one and overcome their fear. to explain these bursts, subgroups' small sizes and leaders' role, a social influence model and a synchronization model are compared.",,12/24/2013,2/2/2018,['bruggeman'],['cs']
17,17,1110.2053,"steps towards a theory of visual information: active perception,   signal-to-symbol conversion and the interplay between sensing and control",['cs.cv'],"this manuscript describes the elements of a theory of information tailored to control and decision tasks and specifically to visual data. the concept of actionable information is described, that relates to a notion of information championed by j. gibson, and a notion of ""complete information"" that relates to the minimal sufficient statistics of a complete representation. it is shown that the ""actionable information gap"" between the two can be reduced by exercising control on the sensing process. thus, senging, control and information are inextricably tied. this has consequences in the so-called ""signal-to-symbol barrier"" problem, as well as in the analysis and design of active sensing systems. it has ramifications in vision-based control, navigation, 3-d reconstruction and rendering, as well as detection, localization, recognition and categorization of objects and scenes in live video.   this manuscript has been developed from a set of lecture notes for a summer course at the first international computer vision summer school (icvss) in scicli, italy, in july of 2008. they were later expanded and amended for subsequent lectures in the same school in july 2009. starting on november 1, 2009, they were further expanded for a special topics course, cs269, taught at ucla in the spring term of 2010.",,10/10/2011,12/27/2017,['soatto'],['math']
18,58,1401.1671,distributed energy efficient channel allocation,"['cs.ni', 'cs.it', 'math.it']","design of energy efficient protocols for modern wireless systems has become an important area of research. in this paper, we propose a distributed optimization algorithm for the channel assignment problem for multiple interfering transceiver pairs that cannot communicate with each other. we first modify the auction algorithm for maximal energy efficiency and show that the problem can be solved without explicit message passing using the carrier sense multiple access (csma) protocols. we then develop a novel scheme by converting the channel assignment problem into perfect matchings on bipartite graphs. the proposed scheme improves the energy efficiency and does not require any explicit message passing or a shared memory between the users. we derive bounds on the convergence rate and show that the proposed algorithm converges faster than the distributed auction algorithm and achieves near-optimal performance under rayleigh fading channels. we also present an asymptotic performance analysis of the fast matching algorithm for energy efficient resource allocation and prove the optimality for large enough number of users and number of channels. finally, we provide numerical assessments that confirm the energy efficiency gains compared to the state of the art.",,1/8/2014,2/15/2018,"['naparstek', 'zafaruddin', 'leshem', 'jorswieck']",['cs']
19,21,1202.3538,refinement modal logic,"['cs.lo', 'cs.ai']","in this paper we present {\em refinement modal logic}. a refinement is like a bisimulation, except that from the three relational requirements only `atoms' and `back' need to be satisfied. our logic contains a new operator 'all' in addition to the standard modalities 'box' for each agent. the operator 'all' acts as a quantifier over the set of all refinements of a given model. as a variation on a bisimulation quantifier, this refinement operator or refinement quantifier 'all' can be seen as quantifying over a variable not occurring in the formula bound by it. the logic combines the simplicity of multi-agent modal logic with some powers of monadic second-order quantification. we present a sound and complete axiomatization of multi-agent refinement modal logic. we also present an extension of the logic to the modal mu-calculus, and an axiomatization for the single-agent version of this logic. examples and applications are also discussed: to software verification and design (the set of agents can also be seen as a set of actions), and to dynamic epistemic logic. we further give detailed results on the complexity of satisfiability, and on succinctness.",10.1016/j.ic.2014.07.013,2/16/2012,12/25/2013,"['bozzelli', 'van ditmarsch', 'french', 'hales', 'pinchinat']",['math']
20,33,1211.6468,"using isabelle to verify special relativity, with application to   hypercomputation theory","['cs.lo', 'gr-qc']","logicians at the r\'enyi mathematical institute in budapest have spent several years developing versions of relativity theory (special, general, and other variants) based wholly on first order logic, and have argued in favour of the physical decidability, via exploitation of cosmological phenomena, of formally undecidable questions such as the halting problem and the consistency of set theory.   the hungarian theories are very extensive, and their associated proofs are intuitively very satisfying, but this brings its own risks since intuition can sometimes be misleading. as part of a joint project, researchers at sheffield have recently started generating rigorous machine-verified versions of the hungarian proofs, so as to demonstrate the soundness of their work. in this paper, we explain the background to the project and demonstrate an isabelle proof of the theorem ""no inertial observer can travel faster than light"".   this approach to physical theories and physical computability has several pay-offs: (a) we can be certain our intuition hasn't led us astray (or if it has, we can identify where this has happened); (b) we can identify which axioms are specifically required in the proof of each theorem and to what extent those axioms can be weakened (the fewer assumptions we make up-front, the stronger the results); and (c) we can identify whether new formal proof techniques and tactics are needed when tackling physical as opposed to mathematical theories.",10.1007/s10817-013-9292-7,11/27/2012,1/18/2013,"['stannett', 'németi']",['cs']
21,29,1210244,"group model selection using marginal correlations: the good, the bad and   the ugly","['math.st', 'cs.it', 'math.it', 'stat.ml', 'stat.th']","group model selection is the problem of determining a small subset of groups of predictors (e.g., the expression data of genes) that are responsible for majority of the variation in a response variable (e.g., the malignancy of a tumor). this paper focuses on group model selection in high-dimensional linear models, in which the number of predictors far exceeds the number of samples of the response variable. existing works on high-dimensional group model selection either require the number of samples of the response variable to be significantly larger than the total number of predictors contributing to the response or impose restrictive statistical priors on the predictors and/or nonzero regression coefficients. this paper provides comprehensive understanding of a low-complexity approach to group model selection that avoids some of these limitations. the proposed approach, termed group thresholding (groth), is based on thresholding of marginal correlations of groups of predictors with the response variable and is reminiscent of existing thresholding-based approaches in the literature. the most important contribution of the paper in this regard is relating the performance of groth to a polynomial-time verifiable property of the predictors for the general case of arbitrary (random or deterministic) predictors and arbitrary nonzero regression coefficients.",10.1109/allerton.2012.6483259,10/8/2012,,"['bajwa', 'mixon']",['math']
22,26,1206.4656,machine learning that matters,"['cs.lg', 'cs.ai', 'stat.ml']","much of current machine learning (ml) research has lost its connection to problems of import to the larger world of science and society. from this perspective, there exist glaring limitations in the data sets we investigate, the metrics we employ for evaluation, and the degree to which results are communicated back to their originating domains. what changes are needed to how we conduct research to increase the impact that ml has? we present six impact challenges to explicitly focus the field?s energy and attention, and we discuss existing obstacles that must be addressed. we aim to inspire ongoing discussion and focus on ml that matters.",,6/18/2012,,['wagstaff'],['cs']
23,38,1305.5592,finite-length and asymptotic analysis of correlogram for undersampled   data,"['cs.it', 'math.it']","this paper studies a spectrum estimation method for the case that the samples are obtained at a rate lower than the nyquist rate. the method is referred to as the correlogram for undersampled data. the algorithm partitions the spectrum into a number of segments and estimates the average power within each spectral segment. this method is able to estimate the power spectrum density of a signal from undersampled data without essentially requiring the signal to be sparse. we derive the bias and the variance of the spectrum estimator, and show that there is a tradeoff between the accuracy of the estimation, the frequency resolution, and the complexity of the estimator. a closed-form approximation of the estimation variance is also derived, which clearly shows how the variance is related to different parameters. the asymptotic behavior of the estimator is also investigated, and it is proved that this spectrum estimator is consistent. moreover, the estimation made for different spectral segments becomes uncorrelated as the signal length tends to infinity. finally, numerical examples and simulation results are provided, which approve the theoretical conclusions.",,5/23/2013,,"['shaghaghi', 'vorobyov']",['math']
24,80,1405.1906,leader-following consensus of multi-agent systems over finite fields,"['math.oc', 'cs.sy']","the leader-following consensus problem of multi-agent systems over finite fields ${\mathbb f}_p$ is considered in this paper. dynamics of each agent is governed by a linear equation over ${\mathbb f}_p$, where a distributed control protocol is utilized by the followers.sufficient and/or necessary conditions on system matrices and graph weights in ${\mathbb f}_p$ are provided for the followers to track the leader.",10.1109/cdc.2014.7039850,5/8/2014,,"['xu', 'hong']",['cs']
25,28,1208.3251,toward resource-optimal consensus over the wireless medium,"['cs.it', 'math.it']","we carry out a comprehensive study of the resource cost of averaging consensus in wireless networks. most previous approaches suppose a graphical network, which abstracts away crucial features of the wireless medium, and measure resource consumption only in terms of the total number of transmissions required to achieve consensus. under a path-loss dominated model, we study the resource requirements of consensus with respect to three wireless-appropriate metrics: total transmit energy, elapsed time, and time-bandwidth product. first we characterize the performance of several popular gossip algorithms, showing that they may be order-optimal with respect to transmit energy but are strictly suboptimal with respect to elapsed time and time-bandwidth product. further, we propose a new consensus scheme, termed hierarchical averaging, and show that it is nearly order-optimal with respect to all three metrics. finally, we examine the effects of quantization, showing that hierarchical averaging provides a nearly order-optimal tradeoff between resource consumption and quantization error.",10.1109/jstsp.2013.2246765,8/15/2012,2/11/2013,"['nokleby', 'bajwa', 'calderbank', 'aazhang']",['math']
26,27,1208.3124,on the computation of zone and double zone diagrams,"['cs.cg', 'math.fa', 'math.mg']","classical objects in computational geometry are defined by explicit relations. several years ago the pioneering works of t. asano, j. matousek and t. tokuyama introduced ""implicit computational geometry"", in which the geometric objects are defined by implicit relations involving sets. an important member in this family is called ""a zone diagram"". the implicit nature of zone diagrams implies, as already observed in the original works, that their computation is a challenging task. in a continuous setting this task has been addressed (briefly) only by these authors in the euclidean plane with point sites. we discuss the possibility to compute zone diagrams in a wide class of spaces and also shed new light on their computation in the original setting. the class of spaces, which is introduced here, includes, in particular, euclidean spheres and finite dimensional strictly convex normed spaces. sites of a general form are allowed and it is shown that a generalization of the iterative method suggested by asano, matousek and tokuyama converges to a double zone diagram, another implicit geometric object whose existence is known in general. occasionally a zone diagram can be obtained from this procedure. the actual (approximate) computation of the iterations is based on a simple algorithm which enables the approximate computation of voronoi diagrams in a general setting. our analysis also yields a few byproducts of independent interest, such as certain topological properties of voronoi cells (e.g., that in the considered setting their boundaries cannot be ""fat"").",10.1007/s00454-017-9958-8,8/14/2012,12/31/2017,['reem'],['cs']
27,35,1302.4118,target estimation in colocated mimo radar via matrix completion,"['cs.it', 'math.it', 'stat.ap']","we consider a colocated mimo radar scenario, in which the receive antennas forward their measurements to a fusion center. based on the received data, the fusion center formulates a matrix which is then used for target parameter estimation. when the receive antennas sample the target returns at nyquist rate, and assuming that there are more receive antennas than targets, the data matrix at the fusion center is low-rank. when each receive antenna sends to the fusion center only a small number of samples, along with the sample index, the receive data matrix has missing elements, corresponding to the samples that were not forwarded. under certain conditions, matrix completion techniques can be applied to recover the full receive data matrix, which can then be used in conjunction with array processing techniques, e.g., music, to obtain target information. numerical results indicate that good target recovery can be achieved with occupancy of the receive data matrix as low as 50%.",10.1109/icassp.2013.6638439,2/17/2013,3/25/2013,"['sun', 'petropulu', 'bajwa']",['math']
28,68,1402.3631,privately solving linear programs,"['cs.ds', 'cs.cr', 'cs.lg']","in this paper, we initiate the systematic study of solving linear programs under differential privacy. the first step is simply to define the problem: to this end, we introduce several natural classes of private linear programs that capture different ways sensitive data can be incorporated into a linear program. for each class of linear programs we give an efficient, differentially private solver based on the multiplicative weights framework, or we give an impossibility result.",10.1007/978-3-662-43948-7_51,2/14/2014,5/8/2014,"['hsu', 'roth', 'roughgarden', 'ullman']",['cs']
29,49,1311.2828,private matchings and allocations,"['cs.gt', 'cs.cr', 'cs.ds']","we consider a private variant of the classical allocation problem: given k goods and n agents with individual, private valuation functions over bundles of goods, how can we partition the goods amongst the agents to maximize social welfare? an important special case is when each agent desires at most one good, and specifies her (private) value for each good: in this case, the problem is exactly the maximum-weight matching problem in a bipartite graph.   private matching and allocation problems have not been considered in the differential privacy literature, and for good reason: they are plainly impossible to solve under differential privacy. informally, the allocation must match agents to their preferred goods in order to maximize social welfare, but this preference is exactly what agents wish to hide. therefore, we consider the problem under the relaxed constraint of joint differential privacy: for any agent i, no coalition of agents excluding i should be able to learn about the valuation function of agent i. in this setting, the full allocation is no longer published---instead, each agent is told what good to get. we first show that with a small number of identical copies of each good, it is possible to efficiently and accurately solve the maximum weight matching problem while guaranteeing joint differential privacy. we then consider the more general allocation problem, when bidder valuations satisfy the gross substitutes condition. finally, we prove that the allocation problem cannot be solved to non-trivial accuracy under joint differential privacy without requiring multiple copies of each type of good.",10.1137/15100271x,11/12/2013,8/19/2016,"['hsu', 'huang', 'roth', 'roughgarden', 'wu']",['math']
30,30,1210.4959,halving lines and their underlying graphs,"['math.co', 'cs.dm']","in this paper we study underlying graphs corresponding to a set of halving lines. we establish many properties of such graphs. in addition, we tighten the upper bound for the number of halving lines.",10.2140/involve.2018.11.1,10/17/2012,,"['khovanova', 'yang']",['cs']
31,32,1211.0877,differential privacy for the analyst via private equilibrium computation,"['cs.ds', 'cs.gt']","we give new mechanisms for answering exponentially many queries from multiple analysts on a private database, while protecting differential privacy both for the individuals in the database and for the analysts. that is, our mechanism's answer to each query is nearly insensitive to changes in the queries asked by other analysts. our mechanism is the first to offer differential privacy on the joint distribution over analysts' answers, providing privacy for data analysts even if the other data analysts collude or register multiple accounts. in some settings, we are able to achieve nearly optimal error rates (even compared to mechanisms which do not offer analyst privacy), and we are able to extend our techniques to handle non-linear queries. our analysis is based on a novel view of the private query-release problem as a two-player zero-sum game, which may be of independent interest.",10.1145/2488608.2488651,11/5/2012,3/22/2013,"['hsu', 'roth', 'ullman']",['math']
32,71,1403.4622,complete simultaneous conjugacy invariants in artin's braid groups,"['math.gr', 'cs.cc', 'cs.cr']","we solve the simultaneous conjugacy problem in artin's braid groups and, more generally, in garside groups, by means of a complete, effectively computable, finite invariant. this invariant generalizes the one-dimensional notion of super summit set to arbitrary dimensions. one key ingredient in our solution is the introduction of a provable high-dimensional version of the birman--ko--lee cycling theorem. the complexity of this solution is a small degree polynomial in the cardinalities of our generalized super summit sets and the input parameters. computer experiments suggest that the cardinality of this invariant, for a list of order $n$ independent elements of artin's braid group $b_n$, is generically close to~1.",,3/18/2014,2/15/2018,"['kalka', 'tsaban', 'vinokur']",['cs']
33,57,1401.1333,time series forecasting using neural networks,['cs.ne'],recent studies have shown the classification and prediction power of the neural networks. it has been demonstrated that a nn can approximate any continuous function. neural networks have been successfully used for forecasting of financial data series. the classical methods used for time series prediction like box-jenkins or arima assumes that there is a linear relationship between inputs and outputs. neural networks have the advantage that can approximate nonlinear functions. in this paper we compared the performances of different feed forward and recurrent neural networks and training algorithms for predicting the exchange rate eur/ron and usd/ron. we used data series with daily exchange rates starting from 2005 until 2013.,,1/7/2014,,"['oancea', 'ciucu']",['cs']
34,99,1409.8229999999999,renoir - a dataset for real low-light image noise reduction,['cs.cv'],"image denoising algorithms are evaluated using images corrupted by artificial noise, which may lead to incorrect conclusions about their performances on real noise. in this paper we introduce a dataset of color images corrupted by natural noise due to low-light conditions, together with spatially and intensity-aligned low noise images of the same scenes. we also introduce a method for estimating the true noise level in our images, since even the low noise images contain small amounts of noise. we evaluate the accuracy of our noise estimation method on real and artificial noise, and investigate the poisson-gaussian noise model. finally, we use our dataset to evaluate six denoising algorithms: active random field, bm3d, bilevel-mrf, multi-layer perceptron, and two versions of nl-means. we show that while the multi-layer perceptron, bilevel-mrf, and nl-means with soft threshold outperform bm3d on gray images with synthetic noise, they lag behind on our dataset.",10.1016/j.jvcir.2018.01.012,9/29/2014,5/8/2017,"['anaya', 'barbu']",['math']
35,16,1103.5034,on understanding and machine understanding,['cs.ai'],"in the present paper, we try to propose a self-similar network theory for the basic understanding. by extending the natural languages to a kind of so called idealy sufficient language, we can proceed a few steps to the investigation of the language searching and the language understanding of ai.   image understanding, and the familiarity of the brain to the surrounding environment are also discussed. group effects are discussed by addressing the essense of the power of influences, and constructing the influence network of a society. we also give a discussion of inspirations.",,3/23/2011,2/1/2018,['chern'],['cs']
36,2,808.0084,on the hitting times of quantum versus random walks,"['quant-ph', 'cs.ds']","in this paper we define new monte carlo type classical and quantum hitting times, and we prove several relationships among these and the already existing las vegas type definitions. in particular, we show that for some marked state the two types of hitting time are of the same order in both the classical and the quantum case.   further, we prove that for any reversible ergodic markov chain $p$, the quantum hitting time of the quantum analogue of $p$ has the same order as the square root of the classical hitting time of $p$. we also investigate the (im)possibility of achieving a gap greater than quadratic using an alternative quantum walk.   finally, we present new quantum algorithms for the detection and finding problems. the complexities of both algorithms are related to the new, potentially smaller, quantum hitting times. the detection algorithm is based on phase estimation and is particularly simple. the finding algorithm combines a similar phase estimation based procedure with ideas of tulsi from his recent theorem for the 2d grid. extending his result, we show that for any state-transitive markov chain with unique marked state, the quantum hitting time is of the same order for both the detection and finding problems.",,8/1/2008,,"['magniez', 'nayak', 'richter', 'santha']",['math']
37,78,1405.0713,further result on acyclic chromatic index of planar graphs,"['math.co', 'cs.dm']","an acyclic edge coloring of a graph $g$ is a proper edge coloring such that every cycle is colored with at least three colors. the acyclic chromatic index $\chiup_{a}'(g)$ of a graph $g$ is the least number of colors in an acyclic edge coloring of $g$. it was conjectured that $\chiup'_{a}(g)\leq \delta(g) + 2$ for any simple graph $g$ with maximum degree $\delta(g)$. in this paper, we prove that every planar graph $g$ admits an acyclic edge coloring with $\delta(g) + 6$ colors.",10.1016/j.dam.2015.07.015,5/4/2014,8/25/2015,"['wang', 'zhang']",['cs']
38,8,911.2746,model selection: two fundamental measures of coherence and their   algorithmic significance,"['cs.it', 'math.it', 'math.st', 'stat.th']","the problem of model selection arises in a number of contexts, such as compressed sensing, subset selection in linear regression, estimation of structures in graphical models, and signal denoising. this paper generalizes the notion of \emph{incoherence} in the existing literature on model selection and introduces two fundamental measures of coherence---termed as the worst-case coherence and the average coherence---among the columns of a design matrix. in particular, it utilizes these two measures of coherence to provide an in-depth analysis of a simple one-step thresholding (ost) algorithm for model selection. one of the key insights offered by the ensuing analysis is that ost is feasible for model selection as long as the design matrix obeys an easily verifiable property. in addition, the paper also characterizes the model-selection performance of ost in terms of the worst-case coherence, \mu, and establishes that ost performs near-optimally in the low signal-to-noise ratio regime for n x c design matrices with \mu = o(n^{-1/2}). finally, in contrast to some of the existing literature on model selection, the analysis in the paper is nonasymptotic in nature, it does not require knowledge of the true model order, it is applicable to generic (random or deterministic) design matrices, and it neither requires submatrices of the design matrix to have full rank, nor does it assume a statistical prior on the values of the nonzero entries of the data vector.",10.1109/isit.2010.5513474,11/15/2009,4/29/2010,"['bajwa', 'calderbank', 'jafarpour']",['math']
39,98,1409.8061,a new dof upper bound and its achievability for $k$-user mimo y channels,"['cs.it', 'math.it']","this work is to study the degrees of freedom (dof) for the $k$-user mimo y channel. previously, two transmission frameworks have been proposed for the dof analysis when $n \geq 2m$, where $m$ and $n$ denote the number of antennas at each source node and the relay node respectively. the first method is named as signal group based alignment proposed by hua et al. in [1]. the second is named as signal pattern approach introduced by wang et al. in [2]. but both of them only studied certain antenna configurations. the maximum achievable dof in the general case still remains unknown. in this work, we first derive a new upper bound of the dof using the genie-aided approach. then, we propose a more general transmission framework, generalized signal alignment (gsa), and show that the previous two methods are both special cases of gsa. with gsa, we prove that the new dof upper bound is achievable when $\frac{n}{m} \in \left(0,2+\frac{4}{k(k-1)}\right] \cup \left[k-2, +\infty\right)$. the dof analysis in this paper provides a major step forward towards the fundamental capacity limit of the $k$-user mimo y channel. it also offers a new approach of integrating interference alignment with physical layer network coding.",10.1109/icc.2015.7249109,9/29/2014,10/11/2014,"['liu', 'tao']",['cs']
40,4,903.0197,rotation distance is fixed-parameter tractable,['cs.ds'],"rotation distance between trees measures the number of simple operations it takes to transform one tree into another. there are no known polynomial-time algorithms for computing rotation distance. in the case of ordered rooted trees, we show that the rotation distance between two ordered trees is fixed-parameter tractable, in the parameter, k, the rotation distance. the proof relies on the kernalization of the initial trees to trees with size bounded by 7k.",,3/1/2009,,"['cleary', 'john']",['math']
41,83,1407.4723,toward selectivity based keyword extraction for croatian news,"['cs.cl', 'cs.ir', 'cs.si']","preliminary report on network based keyword extraction for croatian is an unsupervised method for keyword extraction from the complex network. we build our approach with a new network measure the node selectivity, motivated by the research of the graph based centrality approaches. the node selectivity is defined as the average weight distribution on the links of the single node. we extract nodes (keyword candidates) based on the selectivity value. furthermore, we expand extracted nodes to word-tuples ranked with the highest in/out selectivity values. selectivity based extraction does not require linguistic knowledge while it is purely derived from statistical and structural information en-compassed in the source text which is reflected into the structure of the network. obtained sets are evaluated on a manually annotated keywords: for the set of extracted keyword candidates average f1 score is 24,63%, and average f2 score is 21,19%; for the exacted words-tuples candidates average f1 score is 25,9% and average f2 score is 24,47%.",,7/17/2014,,"['beliga', 'meštrović', 'martinčić-ipšić']",['cs']
42,90,1408.1025,stable throughput region of cognitive-relay networks with imperfect   sensing and finite relaying buffer,['cs.ni'],"in this letter, we obtain the stable throughput region for a cognitive relaying scheme with a finite relaying buffer and imperfect sensing. the analysis investigates the effect of the secondary user's finite relaying capabilities under different scenarios of primary, secondary and relaying links outages. furthermore, we demonstrate the effect of miss detection and false alarm probabilities on the achievable throughput for the primary and secondary users.",,8/5/2014,3/18/2018,['alaa'],['math']
43,3,812.2709,variations on a theme by schalkwijk and kailath,"['cs.it', 'math.it']","schalkwijk and kailath (1966) developed a class of block codes for gaussian channels with ideal feedback for which the probability of decoding error decreases as a second-order exponent in block length for rates below capacity. this well-known but surprising result is explained and simply derived here in terms of a result by elias (1956) concerning the minimum mean-square distortion achievable in transmitting a single gaussian random variable over multiple uses of the same gaussian channel. a simple modification of the schalkwijk-kailath scheme is then shown to have an error probability that decreases with an exponential order which is linearly increasing with block length. in the infinite bandwidth limit, this scheme produces zero error probability using bounded expected energy at all rates below capacity. a lower bound on error probability for the finite bandwidth case is then derived in which the error probability decreases with an exponential order which is linearly increasing in block length at the same rate as the upper bound.",10.1109/tit.2009.2034896,12/14/2008,11/20/2009,"['gallager', 'nakiboglu']",['cs']
44,65,1402.1607,generalized signal alignment for mimo two-way x relay channels,"['cs.it', 'math.it']","we study the degrees of freedom (dof) of mimo two-way x relay channels. previous work studied the case $n < 2m$, where $n$ and $m$ denote the number of antennas at the relay and each source, respectively, and showed that the maximum dof of $2n$ is achievable when $n \leq \lfloor\frac{8m}{5}\rfloor$ by applying signal alignment (sa) for network coding and interference cancelation. this work considers the case $n>2m$ where the performance is limited by the number of antennas at each source node and conventional sa is not feasible. we propose a \textit{generalized signal alignment} (gsa) based transmission scheme. the key is to let the signals to be exchanged between every source node align in a transformed subspace, rather than the direct subspace, at the relay so as to form network-coded signals. this is realized by jointly designing the precoding matrices at all source nodes and the processing matrix at the relay. moreover, the aligned subspaces are orthogonal to each other. by applying the gsa, we show that the dof upper bound $4m$ is achievable when $m \leq \lfloor\frac{2n}{5}\rfloor$ ($m$ is even) or $m \leq \lfloor\frac{2n-1}{5}\rfloor$ ($m$ is odd). numerical results also demonstrate that our proposed transmission scheme is feasible and effective.",10.1109/icc.2014.6884019,2/7/2014,,"['liu', 'tao', 'xiang', 'long']",['math']
45,82,1407.2988,proving differential privacy in hoare logic,"['cs.lo', 'cs.cr']","differential privacy is a rigorous, worst-case notion of privacy-preserving computation. informally, a probabilistic program is differentially private if the participation of a single individual in the input database has a limited effect on the program's distribution on outputs. more technically, differential privacy is a quantitative 2-safety property that bounds the distance between the output distributions of a probabilistic program on adjacent inputs. like many 2-safety properties, differential privacy lies outside the scope of traditional verification techniques. existing approaches to enforce privacy are based on intricate, non-conventional type systems, or customized relational logics. these approaches are difficult to implement and often cumbersome to use.   we present an alternative approach that verifies differential privacy by standard, non-relational reasoning on non-probabilistic programs. our approach transforms a probabilistic program into a non-probabilistic program which simulates two executions of the original program. we prove that if the target program is correct with respect to a hoare specification, then the original probabilistic program is differentially private. we provide a variety of examples from the differential privacy literature to demonstrate the utility of our approach. finally, we compare our approach with existing verification techniques for privacy.",10.1109/csf.2014.36,7/10/2014,,"['barthe', 'gaboardi', 'arias', 'hsu', 'kunz', 'strub']",['cs']
46,43,1309.0671,bayesopt: a library for bayesian optimization with robotics applications,"['cs.ro', 'cs.ai', 'cs.lg', 'cs.ms']","the purpose of this paper is twofold. on one side, we present a general framework for bayesian optimization and we compare it with some related fields in active learning and bayesian numerical analysis. on the other hand, bayesian optimization and related problems (bandits, sequential experimental design) are highly dependent on the surrogate model that is selected. however, there is no clear standard in the literature. thus, we present a fast and flexible toolbox that allows to test and combine different models and criteria with little effort. it includes most of the state-of-the-art contributions, algorithms and models. its speed also removes part of the stigma that bayesian optimization methods are only good for ""expensive functions"". the software is free and it can be used in many operating systems and computer languages.",,9/3/2013,,['martinez-cantin'],['math']
47,34,1212.6751,computably categorical fields via fermat's last theorem,"['math.lo', 'cs.lo']","we construct a computable, computably categorical field of infinite transcendence degree over the rational numbers, using the fermat polynomials and assorted results from algebraic geometry. we also show that this field has an intrinsically computable (infinite) transcendence basis.",,12/30/2012,,"['miller', 'schoutens']",['cs']
48,50,1311.4821,on the complexity of random satisfiability problems with planted   solutions,"['cs.cc', 'cs.dm', 'cs.ds', 'math.co', 'math.pr']","the problem of identifying a planted assignment given a random $k$-sat formula consistent with the assignment exhibits a large algorithmic gap: while the planted solution becomes unique and can be identified given a formula with $o(n\log n)$ clauses, there are distributions over clauses for which the best known efficient algorithms require $n^{k/2}$ clauses. we propose and study a unified model for planted $k$-sat, which captures well-known special cases. an instance is described by a planted assignment $\sigma$ and a distribution on clauses with $k$ literals. we define its distribution complexity as the largest $r$ for which the distribution is not $r$-wise independent ($1 \le r \le k$ for any distribution with a planted assignment).   our main result is an unconditional lower bound, tight up to logarithmic factors, for statistical (query) algorithms [kearns 1998, feldman et. al 2012], matching known upper bounds, which, as we show, can be implemented using a statistical algorithm. since known approaches for problems over distributions have statistical analogues (spectral, mcmc, gradient-based, convex optimization etc.), this lower bound provides a rigorous explanation of the observed algorithmic gap. the proof introduces a new general technique for the analysis of statistical query algorithms. it also points to a geometric paring phenomenon in the space of all planted assignments.   we describe consequences of our lower bounds to feige's refutation hypothesis [feige 2002] and to lower bounds on general convex programs that solve planted $k$-sat. our bounds also extend to other planted $k$-csp models, and, in particular, provide concrete evidence for the security of goldreich's one-way function and the associated pseudorandom generator when used with a sufficiently hard predicate [goldreich 2000].",,11/19/2013,3/6/2018,"['feldman', 'perkins', 'vempala']",['math']
49,46,1310.1861,physical-layer cryptography through massive mimo,"['cs.it', 'cs.cr', 'math.it']","we propose the new technique of physical-layer cryptography based on using a massive mimo channel as a key between the sender and desired receiver, which need not be secret. the goal is for low-complexity encoding and decoding by the desired transmitter-receiver pair, whereas decoding by an eavesdropper is hard in terms of prohibitive complexity. the decoding complexity is analyzed by mapping the massive mimo system to a lattice. we show that the eavesdropper's decoder for the mimo system with m-pam modulation is equivalent to solving standard lattice problems that are conjectured to be of exponential complexity for both classical and quantum computers. hence, under the widely-held conjecture that standard lattice problems are hard to solve in the worst-case, the proposed encryption scheme has a more robust notion of security than that of the most common encryption methods used today such as rsa and diffie-hellman. additionally, we show that this scheme could be used to securely communicate without a pre-shared secret and little computational overhead. thus, by exploiting the physical layer properties of the radio channel, the massive mimo system provides for low-complexity encryption commensurate with the most sophisticated forms of application-layer encryption that are currently known.",10.1109/tit.2017.2715187,10/7/2013,1/10/2017,"['dean', 'goldsmith']",['cs']
50,59,1401358,bits through bufferless queues,"['cs.it', 'math.it']","this paper investigates the capacity of a channel in which information is conveyed by the timing of consecutive packets passing through a queue with independent and identically distributed service times. such timing channels are commonly studied under the assumption of a work-conserving queue. in contrast, this paper studies the case of a bufferless queue that drops arriving packets while a packet is in service. under this bufferless model, the paper provides upper bounds on the capacity of timing channels and establishes achievable rates for the case of bufferless m/m/1 and m/g/1 queues. in particular, it is shown that a bufferless m/m/1 queue at worst suffers less than 10% reduction in capacity when compared to an m/m/1 work-conserving queue.",10.1109/allerton.2013.6736600,12/18/2013,,"['tavan', 'yates', 'bajwa']",['math']
51,77,1404.6898,quantum attacks on classical proof systems - the hardness of quantum   rewinding,"['quant-ph', 'cs.cr']","quantum zero-knowledge proofs and quantum proofs of knowledge are inherently difficult to analyze because their security analysis uses rewinding. certain cases of quantum rewinding are handled by the results by watrous (siam j comput, 2009) and unruh (eurocrypt 2012), yet in general the problem remains elusive. we show that this is not only due to a lack of proof techniques: relative to an oracle, we show that classically secure proofs and proofs of knowledge are insecure in the quantum setting.   more specifically, sigma-protocols, the fiat-shamir construction, and fischlin's proof system are quantum insecure under assumptions that are sufficient for classical security. additionally, we show that for similar reasons, computationally binding commitments provide almost no security guarantees in a quantum setting.   to show these results, we develop the ""pick-one trick"", a general technique that allows an adversary to find one value satisfying a given predicate, but not two.",,4/28/2014,10/19/2014,"['ambainis', 'rosmanis', 'unruh']",['cs']
52,53,1312.2226,on two algorithmic problems about synchronizing automata,"['cs.fl', 'cs.cc']","under the assumption $\mathcal{p} \neq \mathcal{np}$, we prove that two natural problems from the theory of synchronizing automata cannot be solved in polynomial time. the first problem is to decide whether a given reachable partial automaton is synchronizing. the second one is, given an $n$-state binary complete synchronizing automaton, to compute its reset threshold within performance ratio less than $d \ln{(n)}$ for a specific constant $d>0$.",,12/8/2013,3/22/2018,['berlinkov'],['math']
53,19,1111.4662,traffic distributions and independence: permutation invariant random   matrices and the three notions of independence,"['math.pr', 'cs.dm', 'math.co', 'math.oa']","voiculescu's notion of asymptotic free independence is known for a large class of random matrices including independent unitary invariant matrices. this notion is extended for independent random matrices invariant in law by conjugation by permutation matrices. this fact leads naturally to an extension of free probability, formalized under the notions of traffic probability. we first establish this construction for random matrices. we define the traffic distribution of random matrices, which is richer than the *-distribution of free probability. the knowledge of the individual traffic distributions of independent permutation invariant families of matrices is sufficient to compute the limiting distribution of the join family. under a factorization assumption, we call traffic independence the asymptotic rule that plays the role of independence with respect to traffic distributions. wigner matrices, haar unitary matrices and uniform permutation matrices converge in traffic distributions, a fact which yields new results on the limiting *-distributions of several matrices we can construct from them. then we define the abstract traffic spaces as non commutative probability spaces with more structure. we prove that at an algebraic level, traffic independence in some sense unifies the three canonical notions of tensor, free and boolean independence. a central limiting theorem is stated in this context, interpolating between the tensor, free and boolean central limit theorems.",,11/20/2011,3/8/2018,['male'],['cs']
54,70,1403108,new ideas for brain modelling,"['cs.ai', 'q-bio.nc']","this paper describes some biologically-inspired processes that could be used to build the sort of networks that we associate with the human brain. new to this paper, a 'refined' neuron will be proposed. this is a group of neurons that by joining together can produce a more analogue system, but with the same level of control and reliability that a binary neuron would have. with this new structure, it will be possible to think of an essentially binary system in terms of a more variable set of values. the paper also shows how recent research associated with the new model, can be combined with established theories, to produce a more complete picture. the propositions are largely in line with conventional thinking, but possibly with one or two more radical suggestions. an earlier cognitive model can be filled in with more specific details, based on the new research results, where the components appear to fit together almost seamlessly. the intention of the research has been to describe plausible 'mechanical' processes that can produce the appropriate brain structures and mechanisms, but that could be used without the magical 'intelligence' part that is still not fully understood. there are also some important updates from an earlier version of this paper.",,3/5/2014,10/17/2016,['greer'],['math']
55,76,1404.3626,optimal power flow as a polynomial optimization problem,"['math.oc', 'cs.sy']",formulating the alternating current optimal power flow (acopf) as a polynomial optimization problem makes it possible to solve large instances in practice and to guarantee asymptotic convergence in theory.,10.1109/tpwrs.2015.2390037,4/14/2014,11/20/2014,"['ghaddar', 'marecek', 'mevissen']",['cs']
56,25,1204.0839,a constrained random demodulator for sub-nyquist sampling,"['cs.it', 'math.it']","this paper presents a significant modification to the random demodulator (rd) of tropp et al. for sub-nyquist sampling of frequency-sparse signals. the modification, termed constrained random demodulator, involves replacing the random waveform, essential to the operation of the rd, with a constrained random waveform that has limits on its switching rate because fast switching waveforms may be hard to generate cleanly. the result is a relaxation on the hardware requirements with a slight, but manageable, decrease in the recovery guarantees. the paper also establishes the importance of properly choosing the statistics of the constrained random waveform. if the power spectrum of the random waveform matches the distribution on the tones of the input signal (i.e., the distribution is proportional to the power spectrum), then recovery of the input signal tones is improved. the theoretical guarantees provided in the paper are validated through extensive numerical simulations and phase transition plots.",10.1109/tsp.2012.2231077,4/3/2012,12/9/2012,"['harms', 'bajwa', 'calderbank']",['math']
57,96,1409.2612,a simple proof of the completeness of apal,['cs.lo'],we provide a simple proof of the completeness of arbitrary public announcement logic apal. the proof is an improvement over the proof found in the publication knowable as known after an announcement.,,9/9/2014,9/10/2014,"['balbiani', 'van ditmarsch']",['cs']
58,24,1204048,deducing security goals from shape analysis sentences,"['cs.cr', 'cs.lo']","guttman presented a model-theoretic approach to establishing security goals in the context of strand space theory. in his approach, a run of the cryptographic protocol shapes analyzer (cpsa) produces models that determine if a goal is satisfied. this paper presents a method for extracting a sentence that completely characterizes a run of cpsa. logical deduction can then be used to determine if a goal is satisfied. this method has been implemented and is available to all.",,4/2/2012,2/5/2018,['ramsdell'],['math']
59,63,1401.8219,on the properties of the priority deriving procedure in the pairwise   comparisons method,"['cs.dm', 'cs.gt']","the pairwise comparisons method is a convenient tool used when the relative order of preferences among different concepts (alternatives) needs to be determined. there are several popular implementations of this method, including the eigenvector method, the least squares method, the chi squares method and others. each of the above methods comes with one or more inconsistency indices that help to decide whether the consistency of input guarantees obtaining a reliable output, thus taking the optimal decision. this article explores the relationship between inconsistency of input and discrepancy of output. a global ranking discrepancy describes to what extent the obtained results correspond to the single expert's assessments. on the basis of the inconsistency and discrepancy indices, two properties of the weight deriving procedure are formulated. these properties are proven for eigenvector method and koczkodaj's inconsistency index. several estimates using koczkodaj's inconsistency index for a principal eigenvalue, saaty's inconsistency index and the condition of order preservation are also provided.",10.3233/fi-2015-1240,1/31/2014,6/20/2014,['kułakowski'],['cs']
60,7,910.2912,universally composable quantum multi-party computation,"['quant-ph', 'cs.cr']","the universal composability model (uc) by canetti (focs 2001) allows for secure composition of arbitrary protocols. we present a quantum version of the uc model which enjoys the same compositionality guarantees. we prove that in this model statistically secure oblivious transfer protocols can be constructed from commitments. furthermore, we show that every statistically classically uc secure protocol is also statistically quantum uc secure. such implications are not known for other quantum security definitions. as a corollary, we get that quantum uc secure protocols for general multi-party computation can be constructed from commitments.",10.1007/978-3-642-13190-5_25,10/15/2009,,['unruh'],['math']
61,9,1001.1435,"jbotsim, a tool for fast prototyping of distributed algorithms in   dynamic networks","['cs.ms', 'cs.dc', 'cs.ni']","jbotsim is a java library that offers basic primitives for prototyping, running, and visualizing distributed algorithms in dynamic networks. with jbotsim, one can implement an idea in minutes and interact with it ({\it e.g.}, add, move, or delete nodes) while it is running. jbotsim is well suited to prepare live demonstrations of your algorithms to colleagues or students; it can also be used to evaluate performance at the algorithmic level (number of messages, number of rounds, etc.). unlike most tools, jbotsim is not an integrated environment. it is a lightweight library to be used in your program. in this paper, we present an overview of its distinctive features and architecture.",,1/9/2010,3/3/2018,['casteigts'],['cs']
62,5,903.0199,a linear-time approximation algorithm for rotation distance,['cs.ds'],"rotation distance between rooted binary trees measures the number of simple operations it takes to transform one tree into another. there are no known polynomial-time algorithms for computing rotation distance. we give an efficient, linear-time approximation algorithm, which estimates the rotation distance, within a provable factor of 2, between ordered rooted binary trees. .",,3/1/2009,7/7/2009,"['cleary', 'john']",['math']
63,61,1401.6312,predicate logic as a modelling language: the idp system,['cs.lo'],"with the technology of the time, kowalski's seminal 1974 paper {\em predicate logic as a programming language} was a breakthrough for the use of logic in computer science. it introduced two fundamental ideas: on the declarative side, the use of the horn clause logic fragment of classical logic, which was soon extended with negation as failure, on the procedural side the procedural interpretation which made it possible to write algorithms in the formalism.   since then, strong progress was made both on the declarative understanding of the logic programming formalism and in automated reasoning technologies, particularly in sat solving, constraint programming and answer set programming. this has paved the way for the development of an extension of logic programming that embodies a more pure view of logic as a modelling language and its role for problem solving.   in this paper, we present the \idp language and system. the language is essentially classical logic extended with one of logic programmings most important contributions to knowledge representation: the representation of complex definitions as rule sets under well-founded semantics. the system is a knowledge base system: a system in which complex declarative information is stored in a knowledge base which can be used to solve different computational problems by applying multiple forms of inference. in this view, theories are declarative modellings, bags of information, descriptions of possible states of affairs. they are neither procedures nor descriptions of computational problems. as such, the \idp language and system preserve the fundamental idea of a declarative reading of logic programs, while they break with the fundamental idea of the procedural interpretation of logic programs.",,1/24/2014,3/13/2018,"['de cat', 'bogaerts', 'bruynooghe', 'janssens', 'denecker']",['cs']
64,41,1308.0776,dynamic approximate all-pairs shortest paths: breaking the o(mn) barrier   and derandomization,['cs.ds'],"we study dynamic $(1+\epsilon)$-approximation algorithms for the all-pairs shortest paths problem in unweighted undirected $n$-node $m$-edge graphs under edge deletions. the fastest algorithm for this problem is a randomized algorithm with a total update time of $\tilde o(mn/\epsilon)$ and constant query time by roditty and zwick [focs 2004]. the fastest deterministic algorithm is from a 1981 paper by even and shiloach [jacm 1981]; it has a total update time of $o(mn^2)$ and constant query time. we improve these results as follows: (1) we present an algorithm with a total update time of $\tilde o(n^{5/2}/\epsilon)$ and constant query time that has an additive error of $2$ in addition to the $1+\epsilon$ multiplicative error. this beats the previous $\tilde o(mn/\epsilon)$ time when $m=\omega(n^{3/2})$. note that the additive error is unavoidable since, even in the static case, an $o(n^{3-\delta})$-time (a so-called truly subcubic) combinatorial algorithm with $1+\epsilon$ multiplicative error cannot have an additive error less than $2-\epsilon$, unless we make a major breakthrough for boolean matrix multiplication [dor et al. focs 1996] and many other long-standing problems [vassilevska williams and williams focs 2010]. the algorithm can also be turned into a $(2+\epsilon)$-approximation algorithm (without an additive error) with the same time guarantees, improving the recent $(3+\epsilon)$-approximation algorithm with $\tilde o(n^{5/2+o(\sqrt{\log{(1/\epsilon)}/\log n})})$ running time of bernstein and roditty [soda 2011] in terms of both approximation and time guarantees. (2) we present a deterministic algorithm with a total update time of $\tilde o(mn/\epsilon)$ and a query time of $o(\log\log n)$. the algorithm has a multiplicative error of $1+\epsilon$ and gives the first improved deterministic algorithm since 1981. it also answers an open question raised by bernstein [stoc 2013].",10.1137/140957299,8/4/2013,6/16/2015,"['henzinger', 'krinninger', 'nanongkai']",['math']
65,23,1202491,distributed private heavy hitters,"['cs.ds', 'cs.cr', 'cs.db']","in this paper, we give efficient algorithms and lower bounds for solving the heavy hitters problem while preserving differential privacy in the fully distributed local model. in this model, there are n parties, each of which possesses a single element from a universe of size n. the heavy hitters problem is to find the identity of the most common element shared amongst the n parties. in the local model, there is no trusted database administrator, and so the algorithm must interact with each of the $n$ parties separately, using a differentially private protocol. we give tight information-theoretic upper and lower bounds on the accuracy to which this problem can be solved in the local model (giving a separation between the local model and the more common centralized model of privacy), as well as computationally efficient algorithms even in the case where the data universe n may be exponentially large.",10.1007/978-3-642-31594-7_39,2/22/2012,11/6/2014,"['hsu', 'khanna', 'roth']",['cs']
66,6,903.4386,error-and-erasure decoding for block codes with feedback,"['cs.it', 'math.it']","inner and outer bounds are derived on the optimal performance of fixed length block codes on discrete memoryless channels with feedback and errors-and-erasures decoding. first an inner bound is derived using a two phase encoding scheme with communication and control phases together with the optimal decoding rule for the given encoding scheme, among decoding rules that can be represented in terms of pairwise comparisons between the messages. then an outer bound is derived using a generalization of the straight-line bound to errors-and-erasures decoders and the optimal error exponent trade off of a feedback encoder with two messages. in addition upper and lower bounds are derived, for the optimal erasure exponent of error free block codes in terms of the rate. finally we present a proof of the fact that the optimal trade off between error exponents of a two message code does not increase with feedback on dmcs.",10.1109/tit.2011.2169529,3/25/2009,9/1/2011,"['nakiboglu', 'zheng']",['cs']
67,47,1310.6324,on jacobian group arithmetic for typical divisors on curves,"['math.nt', 'cs.sc', 'math.ag']","in a previous joint article with f. abu salem, we gave efficient algorithms for jacobian group arithmetic of ""typical"" divisor classes on c_{3,4} curves, improving on similar results by other authors. at that time, we could only state that a generic divisor was typical, and hence unlikely to be encountered if one implemented these algorithms over a very large finite field. this article pins down an explicit characterization of these typical divisors, for an arbitrary smooth projective curve of genus g >= 1 having at least one rational point. we give general algorithms for jacobian group arithmetic with these typical divisors, and prove not only that the algorithms are correct if various divisors are typical, but also that the success of our algorithms provides a guarantee that the resulting output is correct and that the resulting input and/or output divisors are also typical. these results apply in particular to our earlier algorithms for c_{3,4} curves. as a byproduct, we obtain a further speedup of approximately 15% on our previous algorithms for c_{3,4} curves.",10.1007/s40993-018-0101-6,10/23/2013,11/14/2017,['khuri-makdisi'],['math']
68,12,1008.0851,identification of parametric underspread linear systems and   super-resolution radar,"['cs.it', 'math.it']","identification of time-varying linear systems, which introduce both time-shifts (delays) and frequency-shifts (doppler-shifts), is a central task in many engineering applications. this paper studies the problem of identification of underspread linear systems (ulss), whose responses lie within a unit-area region in the delay doppler space, by probing them with a known input signal. it is shown that sufficiently-underspread parametric linear systems, described by a finite set of delays and doppler-shifts, are identifiable from a single observation as long as the time bandwidth product of the input signal is proportional to the square of the total number of delay doppler pairs in the system. in addition, an algorithm is developed that enables identification of parametric ulss from an input train of pulses in polynomial time by exploiting recent results on sub-nyquist sampling for time delay estimation and classical results on recovery of frequencies from a sum of complex exponentials. finally, application of these results to super-resolution target detection using radar is discussed. specifically, it is shown that the proposed procedure allows to distinguish between multiple targets with very close proximity in the delay doppler space, resulting in a resolution that substantially exceeds that of standard matched-filtering based techniques without introducing leakage effects inherent in recently proposed compressed sensing-based radar methods.",10.1109/tsp.2011.2114657,8/4/2010,12/7/2010,"['bajwa', 'gedalyahu', 'eldar']",['cs']
69,92,1408.2467,matrix completion under interval uncertainty,"['math.oc', 'cs.ai', 'cs.ir']","matrix completion under interval uncertainty can be cast as matrix completion with element-wise box constraints. we present an efficient alternating-direction parallel coordinate-descent method for the problem. we show that the method outperforms any other known method on a benchmark in image in-painting in terms of signal-to-noise ratio, and that it provides high-quality solutions for an instance of collaborative filtering with 100,198,805 recommendations within 5 minutes.",10.1016/j.ejor.2016.07.014,8/11/2014,4/1/2016,"['marecek', 'richtarik', 'takac']",['math']
70,14,1101.1934,bit-wise unequal error protection for variable length block codes with   feedback,"['cs.it', 'math.it']","the bit-wise unequal error protection problem, for the case when the number of groups of bits $\ell$ is fixed, is considered for variable length block codes with feedback. an encoding scheme based on fixed length block codes with erasures is used to establish inner bounds to the achievable performance for finite expected decoding time. a new technique for bounding the performance of variable length block codes is used to establish outer bounds to the performance for a given expected decoding time. the inner and the outer bounds match one another asymptotically and characterize the achievable region of rate-exponent vectors, completely. the single message message-wise unequal error protection problem for variable length block codes with feedback is also solved as a necessary step on the way.",10.1109/tit.2012.2227671,1/10/2011,12/17/2012,"['nakiboglu', 'gorantla', 'zheng', 'coleman']",['cs']
71,0,704.3504,smooth r\'enyi entropy of ergodic quantum information sources,"['quant-ph', 'cs.it', 'math.it']","we prove that the average smooth renyi entropy rate will approach the entropy rate of a stationary, ergodic information source, which is equal to the shannon entropy rate for a classical information source and the von neumann entropy rate for a quantum information source.",,4/26/2007,,"['schoenmakers', 'tjoelker', 'tuyls', 'verbitskiy']",['math']
72,84,1407.4729,sparse partially linear additive models,"['stat.me', 'cs.lg', 'stat.ml']","the generalized partially linear additive model (gplam) is a flexible and interpretable approach to building predictive models. it combines features in an additive manner, allowing each to have either a linear or nonlinear effect on the response. however, the choice of which features to treat as linear or nonlinear is typically assumed known. thus, to make a gplam a viable approach in situations in which little is known $a~priori$ about the features, one must overcome two primary model selection challenges: deciding which features to include in the model and determining which of these features to treat nonlinearly. we introduce the sparse partially linear additive model (splam), which combines model fitting and $both$ of these model selection challenges into a single convex optimization problem. splam provides a bridge between the lasso and sparse additive models. through a statistical oracle inequality and thorough simulation, we demonstrate that splam can outperform other methods across a broad spectrum of statistical regimes, including the high-dimensional ($p\gg n$) setting. we develop efficient algorithms that are applied to real data sets with half a million samples and over 45,000 features with excellent predictive performance.",,7/17/2014,3/27/2018,"['lou', 'bien', 'caruana', 'gehrke']",['cs']
73,1,803257,unequal error protection: an information theoretic perspective,"['cs.it', 'cs.dm', 'math.co', 'math.it']","an information theoretic framework for unequal error protection is developed in terms of the exponential error bounds. the fundamental difference between the bit-wise and message-wise unequal error protection (uep) is demonstrated, for fixed length block codes on dmcs without feedback. effect of feedback is investigated via variable length block codes. it is shown that, feedback results in a significant improvement in both bit-wise and message-wise uep (except the single message case for missed detection). the distinction between false-alarm and missed-detection formalizations for message-wise uep is also considered. all results presented are at rates close to capacity.",10.1109/tit.2009.2032819,3/18/2008,10/25/2009,"['borade', 'nakiboglu', 'zheng']",['math']
74,73,1404.2458,r-extreme signalling for congestion control,"['math.oc', 'cs.ai', 'cs.ma']","in many ""smart city"" applications, congestion arises in part due to the nature of signals received by individuals from a central authority. in the model of marecek et al. [arxiv:1406.7639, int. j. control 88(10), 2015], each agent uses one out of multiple resources at each time instant. the per-use cost of a resource depends on the number of concurrent users. a central authority has up-to-date knowledge of the congestion across all resources and uses randomisation to provide a scalar or an interval for each resource at each time. in this paper, the interval to broadcast per resource is obtained by taking the minima and maxima of costs observed within a time window of length r, rather than by randomisation. we show that the resulting distribution of agents across resources also converges in distribution, under plausible assumptions about the evolution of the population over time.",10.1080/00207179.2016.1146968,4/9/2014,3/31/2016,"['marecek', 'shorten', 'yu']",['cs']
75,37,1303.2054,mining representative unsubstituted graph patterns using prior   similarity matrix,"['cs.ce', 'cs.lg']","one of the most powerful techniques to study protein structures is to look for recurrent fragments (also called substructures or spatial motifs), then use them as patterns to characterize the proteins under study. an emergent trend consists in parsing proteins three-dimensional (3d) structures into graphs of amino acids. hence, the search of recurrent spatial motifs is formulated as a process of frequent subgraph discovery where each subgraph represents a spatial motif. in this scope, several efficient approaches for frequent subgraph discovery have been proposed in the literature. however, the set of discovered frequent subgraphs is too large to be efficiently analyzed and explored in any further process. in this paper, we propose a novel pattern selection approach that shrinks the large number of discovered frequent subgraphs by selecting the representative ones. existing pattern selection approaches do not exploit the domain knowledge. yet, in our approach we incorporate the evolutionary information of amino acids defined in the substitution matrices in order to select the representative subgraphs. we show the effectiveness of our approach on a number of real datasets. the results issued from our experiments show that our approach is able to considerably decrease the number of motifs while enhancing their interestingness.",10.1016/j.is.2017.05.006,3/8/2013,,"['dhifli', 'saidi', 'nguifo']",['math']
76,86,1407.6169,multiplicative complexity of vector valued boolean functions,['cs.cc'],"we consider the multiplicative complexity of boolean functions with multiple bits of output, studying how large a multiplicative complexity is necessary and sufficient to provide a desired nonlinearity. for so-called $\sigma\pi\sigma$ circuits, we show that there is a tight connection between error correcting codes and circuits computing functions with high nonlinearity. combining this with known coding theory results, we show that functions with $n$ inputs and $n$ outputs with the highest possible nonlinearity must have at least $2.32n$ and gates. we further show that one cannot prove stronger lower bounds by only appealing to the nonlinearity of a function; we show a bilinear circuit computing a function with almost optimal nonlinearity with the number of and gates being exactly the length of such a shortest code.   additionally we provide a function which, for general circuits, has multiplicative complexity at least $2n-3$.   finally we study the multiplicative complexity of ""almost all"" functions. we show that every function with $n$ bits of input and $m$ bits of output can be computed using at most $2.5(1+o(1))\sqrt{m2^n}$ and gates.",,7/23/2014,2/22/2018,"['find', 'boyar']",['cs']
77,62,1401.7479999999998,np is contained in dtime(n^o(log^{gamma})),['cs.cc'],we use existential diophantine predicates carefully reinterpreted over the reals and the time complexity of tarski algebra to show that 3-cnf sat is in n^o(log^{gamma} n) time for an absolute positive constant gamma.,,1/29/2014,3/9/2018,['litow'],['math']
78,40,1307.2783,coping with unreliable workers in internet-based computing: an   evaluation of reputation mechanisms,"['cs.dc', 'cs.gt']","we present reputation-based mechanisms for building reliable task computing systems over the internet. the most characteristic examples of such systems are the volunteer computing and the crowdsourcing platforms. in both examples end users are offering over the internet their computing power or their human intelligence to solve tasks either voluntarily or under payment. while the main advantage of these systems is the inexpensive computational power provided, the main drawback is the untrustworthy nature of the end users. generally, this type of systems are modeled under the ""master-worker"" setting. a ""master"" has a set of tasks to compute and instead of computing them locally she sends these tasks to available ""workers"" that compute and report back the task results. we categorize these workers in three generic types: altruistic, malicious and rational. altruistic workers that always return the correct result, malicious workers that always return an incorrect result, and rational workers that decide to reply or not truthfully depending on what increases their benefit. we design a reinforcement learning mechanism to induce a correct behavior to rational workers, while the mechanism is complemented by four reputation schemes that cope with malice. the goal of the mechanism is to reach a state of eventual correctness, that is, a stable state of the system in which the master always obtains the correct task results. analysis of the system gives provable guarantees under which truthful behavior can be ensured. finally, we observe the behavior of the mechanism through simulations that use realistic system parameters values. simulations not only agree with the analysis but also reveal interesting trade-offs between various metrics and parameters. finally, the four reputation schemes are assessed against the tolerance to cheaters.",,7/10/2013,3/19/2018,"['christoforou', 'anta', 'georgiou', 'mosteiro', 'sanchez']",['cs']
79,81,1406.1758,scaling limits and influence of the seed graph in preferential   attachment trees,"['math.pr', 'cs.dm', 'math.st', 'stat.th']","we are interested in the asymptotics of random trees built by linear preferential attachment, also known in the literature as barab\'asi-albert trees or plane-oriented recursive trees. we first prove a conjecture of bubeck, mossel \& r\'acz concerning the influence of the seed graph on the asymptotic behavior of such trees. separately we study the geometric structure of nodes of large degrees in a plane version of barab\'asi-albert trees via their associated looptrees. as the number of nodes grows, we show that these looptrees, appropriately rescaled, converge in the gromov-hausdorff sense towards a random compact metric space which we call the brownian looptree. the latter is constructed as a quotient space of aldous' brownian continuum random tree and is shown to have almost sure hausdorff dimension $2$.",,6/6/2014,,"['curien', 'duquesne', 'kortchemski', 'manolescu']",['math']
80,31,1210.5065,realizability algebras iii: some examples,"['cs.lo', 'math.lo']","we use the technique of ""classical realizability"" to build new models of zf + dc in which r is not well ordered. this gives new relative consistency results, probably not obtainable by forcing. this gives also a new method to get programs from proofs of arithmetical formulas with dependent choice.",10.1017/s0960129516000050,10/18/2012,10/2/2013,['krivine'],['cs']
81,20,1112.0857,i/o efficient bisimulation partitioning on very large directed acyclic   graphs,"['cs.ds', 'cs.db']","in this paper we introduce the first efficient external-memory algorithm to compute the bisimilarity equivalence classes of a directed acyclic graph (dag). dags are commonly used to model data in a wide variety of practical applications, ranging from xml documents and data provenance models, to web taxonomies and scientific workflows. in the study of efficient reasoning over massive graphs, the notion of node bisimilarity plays a central role. for example, grouping together bisimilar nodes in an xml data set is the first step in many sophisticated approaches to building indexing data structures for efficient xpath query evaluation. to date, however, only internal-memory bisimulation algorithms have been investigated. as the size of real-world dag data sets often exceeds available main memory, storage in external memory becomes necessary. hence, there is a practical need for an efficient approach to computing bisimulation in external memory.   our general algorithm has a worst-case io-complexity of o(sort(|n| + |e|)), where |n| and |e| are the numbers of nodes and edges, resp., in the data graph and sort(n) is the number of accesses to external memory needed to sort an input of size n. we also study specializations of this algorithm to common variations of bisimulation for tree-structured xml data sets. we empirically verify efficient performance of the algorithms on graphs and xml documents having billions of nodes and edges, and find that the algorithms can process such graphs efficiently even when very limited internal memory is available. the proposed algorithms are simple enough for practical implementation and use, and open the door for further study of external-memory bisimulation algorithms. to this end, the full open-source c++ implementation has been made freely available.",10.1145/2213836.2213899,12/5/2011,,"['hellings', 'fletcher', 'haverkort']",['math']
82,22,1202.4707,a para-model agent for dynamical systems,"['math.oc', 'cs.sy']","consider a dynamical system $u \mapsto x, \dot{x} = f_{nl}(x,u)$ where $f_{nl}$ is a nonlinear (convex or nonconvex) function, or a combination of nonlinear functions that can eventually switch. we present, in this preliminary work, a generalization of the standard model-free control, that can either control the dynamical system, given an output reference trajectory, or optimize the dynamical system as a derivative-free optimization based ""extremum-seeking"" procedure. multiple applications are presented and the robustness of the proposed method is studied in simulation.",,2/21/2012,3/11/2018,['michel'],['cs']
83,67,1402.3329,differential privacy: an economic method for choosing epsilon,['cs.db'],"differential privacy is becoming a gold standard for privacy research; it offers a guaranteed bound on loss of privacy due to release of query results, even under worst-case assumptions. the theory of differential privacy is an active research area, and there are now differentially private algorithms for a wide range of interesting problems.   however, the question of when differential privacy works in practice has received relatively little attention. in particular, there is still no rigorous method for choosing the key parameter $\epsilon$, which controls the crucial tradeoff between the strength of the privacy guarantee and the accuracy of the published results.   in this paper, we examine the role that these parameters play in concrete applications, identifying the key questions that must be addressed when choosing specific values. this choice requires balancing the interests of two different parties: the data analyst and the prospective participant, who must decide whether to allow their data to be included in the analysis. we propose a simple model that expresses this balance as formulas over a handful of parameters, and we use our model to choose $\epsilon$ on a series of simple statistical studies. we also explore a surprising insight: in some circumstances, a differentially private study can be more accurate than a non-private study for the same cost, under our model. finally, we discuss the simplifying assumptions in our model and outline a research agenda for possible refinements.",10.1109/csf.2014.35,2/13/2014,,"['hsu', 'gaboardi', 'haeberlen', 'khanna', 'narayan', 'pierce', 'roth']",['math']
84,66,1402.3210000000001,on the convergence of approximate message passing with arbitrary   matrices,"['cs.it', 'math.it']","approximate message passing (amp) methods and their variants have attracted considerable recent attention for the problem of estimating a random vector $\mathbf{x}$ observed through a linear transform $\mathbf{a}$. in the case of large i.i.d. zero-mean gaussian $\mathbf{a}$, the methods exhibit fast convergence with precise analytic characterizations on the algorithm behavior. however, the convergence of amp under general transforms $\mathbf{a}$ is not fully understood. in this paper, we provide sufficient conditions for the convergence of a damped version of the generalized amp (gamp) algorithm in the case of quadratic cost functions (i.e., gaussian likelihood and prior). it is shown that, with sufficient damping, the algorithm is guaranteed to converge, although the amount of damping grows with peak-to-average ratio of the squared singular values of the transforms $\mathbf{a}$. this result explains the good performance of amp on i.i.d. gaussian transforms $\mathbf{a}$, but also their difficulties with ill-conditioned or non-zero-mean transforms $\mathbf{a}$. a related sufficient condition is then derived for the local stability of the damped gamp method under general cost functions, assuming certain strict convexity conditions.",,2/13/2014,3/2/2018,"['rangan', 'schniter', 'fletcher', 'sarkar']",['cs']
85,51,1312.0049,one-class classification: taxonomy of study and review of techniques,"['cs.lg', 'cs.ai']","one-class classification (occ) algorithms aim to build classification models when the negative class is either absent, poorly sampled or not well defined. this unique situation constrains the learning of efficient classifiers by defining class boundary just with the knowledge of positive class. the occ problem has been considered and applied under many research themes, such as outlier/novelty detection and concept learning. in this paper we present a unified view of the general problem of occ by presenting a taxonomy of study for occ problems, which is based on the availability of training data, algorithms used and the application domains applied. we further delve into each of the categories of the proposed taxonomy and present a comprehensive literature review of the occ algorithms, techniques and methodologies with a focus on their significance, limitations and applications. we conclude our paper by discussing some open research problems in the field of occ and present our vision for future research.",10.1017/s026988891300043x,11/29/2013,,"['khan', 'madden']",['math']
86,88,1408.0135,"new data, new possibilities: exploring the insides of altmetric.com",['cs.dl'],"this paper analyzes altmetric.com, one of the most important altmetric data providers currently used. we have analyzed a set of publications with doi number indexed in the web of science during the period 2011-2013 and collected their data with the altmetric api. 19% of the original set of papers was retrieved from altmetric.com including some altmetric data. we identified 16 different social media sources from which altmetric.com retrieves data. however five of them cover 95.5% of the total set. twitter (87.1%) and mendeley (64.8%) have the highest coverage. we conclude that altmetric.com is a transparent, rich and accurate tool for altmetric data. nevertheless, there are still potential limitations on its exhaustiveness as well as on the selection of social media sources that need further research.",10.3145/epi.2014.jul.03,8/1/2014,,"['robinson-garcía', 'torres-salinas', 'zahedi', 'costas']",['cs']
87,52,1312.1001,optimal detection of intersections between convex polyhedra,['cs.cg'],"for a polyhedron $p$ in $\mathbb{r}^d$, denote by $|p|$ its combinatorial complexity, i.e., the number of faces of all dimensions of the polyhedra. in this paper, we revisit the classic problem of preprocessing polyhedra independently so that given two preprocessed polyhedra $p$ and $q$ in $\mathbb{r}^d$, each translated and rotated, their intersection can be tested rapidly.   for $d=3$ we show how to perform such a test in $o(\log |p| + \log |q|)$ time after linear preprocessing time and space. this running time is the best possible and improves upon the last best known query time of $o(\log|p| \log|q|)$ by dobkin and kirkpatrick (1990).   we then generalize our method to any constant dimension $d$, achieving the same optimal $o(\log |p| + \log |q|)$ query time using a representation of size $o(|p|^{\lfloor d/2\rfloor + \varepsilon})$ for any $\varepsilon>0$ arbitrarily small. this answers an even older question posed by dobkin and kirkpatrick 30 years ago.   in addition, we provide an alternative $o(\log |p| + \log |q|)$ algorithm to test the intersection of two convex polygons $p$ and $q$ in the plane.",,12/3/2013,2/19/2018,"['barba', 'langerman']",['math']
88,60,1401.5791,advanced signal processing techniqes to study normal and epileptic eeg,['cs.ce'],"eeg monitoring has an important milestone provide valuable information of those candidates who suffer from epilepsy.in this paper human normal and epileptic electroencephalogram signals are analyzed with popular and efficient signal processing techniques like fourier and wavelet transform. the delta, theta, alpha, beta and gamma sub bands of eeg are obtained and studied for detection of seizure and epilepsy. the extracted feature is then applied to ann for classification of the eeg signals.",,1/22/2014,,['dash'],['cs']
89,15,1103.1091,a generalization of hopcroft-karp algorithm for semi-matchings and   covers in bipartite graphs (maximum semi-matching problem in bipartite   graphs),['cs.ds'],"an $(f,g)$-semi-matching in a bipartite graph $g=(u \cup v,e)$ is a set of edges $m \subseteq e$ such that each vertex $u\in u$ is incident with at most $f(u)$ edges of $m$, and each vertex $v\in v$ is incident with at most $g(v)$ edges of $m$. in this paper we give an algorithm that for a graph with $n$ vertices and $m$ edges, $n\le m$, constructs a maximum $(f,g)$-semi-matching in running time $o(m\cdot \min (\sqrt{\sum_{u\in u}f(u)}, \sqrt{\sum_{v\in v}g(v)}))$. using the reduction of [5], our result on maximum $(f,g)$-semi-matching problem directly implies an algorithm for the optimal semi-matching problem with running time $o(\sqrt{n}m \log n)$.",10.7151/dmgt.1694,3/5/2011,3/27/2018,"['katrenic', 'semanisin']",['math']
90,11,1006.0719,why gabor frames? two fundamental measures of coherence and their role   in model selection,"['math.st', 'cs.it', 'math.it', 'stat.ml', 'stat.th']","this paper studies non-asymptotic model selection for the general case of arbitrary design matrices and arbitrary nonzero entries of the signal. in this regard, it generalizes the notion of incoherence in the existing literature on model selection and introduces two fundamental measures of coherence---termed as the worst-case coherence and the average coherence---among the columns of a design matrix. it utilizes these two measures of coherence to provide an in-depth analysis of a simple, model-order agnostic one-step thresholding (ost) algorithm for model selection and proves that ost is feasible for exact as well as partial model selection as long as the design matrix obeys an easily verifiable property. one of the key insights offered by the ensuing analysis in this regard is that ost can successfully carry out model selection even when methods based on convex optimization such as the lasso fail due to the rank deficiency of the submatrices of the design matrix. in addition, the paper establishes that if the design matrix has reasonably small worst-case and average coherence then ost performs near-optimally when either (i) the energy of any nonzero entry of the signal is close to the average signal energy per nonzero entry or (ii) the signal-to-noise ratio in the measurement system is not too high. finally, two other key contributions of the paper are that (i) it provides bounds on the average coherence of gaussian matrices and gabor frames, and (ii) it extends the results on model selection using ost to low-complexity, model-order agnostic recovery of sparse signals with arbitrary nonzero entries.",10.1109/jcn.2010.6388466,6/3/2010,7/2/2010,"['bajwa', 'calderbank', 'jafarpour']",['cs']
91,64,1402.1526,dual query: practical private query release for high dimensional data,"['cs.ds', 'cs.cr', 'cs.db', 'cs.lg']","we present a practical, differentially private algorithm for answering a large number of queries on high dimensional datasets. like all algorithms for this task, ours necessarily has worst-case complexity exponential in the dimension of the data. however, our algorithm packages the computationally hard step into a concisely defined integer program, which can be solved non-privately using standard solvers. we prove accuracy and privacy theorems for our algorithm, and then demonstrate experimentally that our algorithm performs well in practice. for example, our algorithm can efficiently and accurately answer millions of queries on the netflix dataset, which has over 17,000 attributes; this is an improvement on the state of the art by multiple orders of magnitude.",,2/6/2014,11/18/2015,"['gaboardi', 'arias', 'hsu', 'roth', 'wu']",['math']
92,87,1407.6845,higher-order approximate relational refinement types for mechanism   design and differential privacy,"['cs.pl', 'cs.gt']","mechanism design is the study of algorithm design in which the inputs to the algorithm are controlled by strategic agents, who must be incentivized to faithfully report them. unlike typical programmatic properties, it is not sufficient for algorithms to merely satisfy the property---incentive properties are only useful if the strategic agents also believe this fact.   verification is an attractive way to convince agents that the incentive properties actually hold, but mechanism design poses several unique challenges: interesting properties can be sophisticated relational properties of probabilistic computations involving expected values, and mechanisms may rely on other probabilistic properties, like differential privacy, to achieve their goals.   we introduce a relational refinement type system, called $\mathsf{hoare}^2$, for verifying mechanism design and differential privacy. we show that $\mathsf{hoare}^2$ is sound w.r.t. a denotational semantics, and correctly models $(\epsilon,\delta)$-differential privacy; moreover, we show that it subsumes dfuzz, an existing linear dependent type system for differential privacy. finally, we develop an smt-based implementation of $\mathsf{hoare}^2$ and use it to verify challenging examples of mechanism design, including auctions and aggregative games, and new proposed examples from differential privacy.",10.1145/2676726.2677000,7/25/2014,10/29/2014,"['barthe', 'gaboardi', 'arias', 'hsu', 'roth', 'strub']",['cs']
93,36,1302.4808,verifying the consistency of remote untrusted services with   conflict-free operations,['cs.dc'],"a group of mutually trusting clients outsources a computation service to a remote server, which they do not fully trust and that may be subject to attacks. the clients do not communicate with each other and would like to verify the correctness of the remote computation and the consistency of the server's responses. this paper presents the conflict-free operation verification protocol (cop) that ensures linearizability when the server is correct and preserves fork-linearizability in any other case. all clients that observe each other's operations are consistent, in the sense that their own operations and those operations of other clients that they see are linearizable. if the server forks two clients by hiding an operation, these clients never again see operations of each other. cop supports wait-free client operations in the sense that when executed with a correct server, non-conflicting operations can run without waiting for other clients, allowing more parallelism than earlier protocols. a conflict arises when an operation causes a subsequent operation to produce a different output value for the client who runs it. the paper gives a precise model for the guarantees of cop and includes a formal analysis that these are achieved.",10.1007/978-3-319-14472-6_1,2/20/2013,3/26/2018,"['cachin', 'ohrimenko']",['math']
94,79,1405.0718,generalized signal alignment: on the achievable dof for multi-user mimo   two-way relay channels,"['cs.it', 'math.it']","this paper studies the achievable degrees of freedom for multi-user mimo two-way relay channels, where there are $k$ source nodes, each equipped with $m$ antennas, one relay node, equipped with $n$ antennas, and each source node exchanges independent messages with an arbitrary set of other source nodes via the relay. by allowing an arbitrary information exchange pattern, the considered channel model is a unified one. it includes several existing channel models as special cases: $k$-user mimo y channel, multi-pair mimo two-way relay channel, generalized mimo two-way x relay channel, and $l$-cluster mimo multiway relay channel. previous studies mainly considered the achievability of the dof cut-set bound $2n$ at the antenna configuration $n < 2m$ by applying signal alignment. this work aims to investigate the achievability of the dof cut-set bound $km$ for the case $n\geq 2m$. to this end, we first derive tighter dof upper bounds for three special cases of the considered channel model. then, we propose a new transmission framework, generalized signal alignment, to approach these bounds. the notion of gsa is to form network-coded symbols by aligning every pair of signals to be exchanged in a compressed subspace at the relay. a necessary and sufficient condition to construct the relay compression matrix is given. we show that using gsa, the new dof upper bound is achievable when i) $\frac{n}{m} \in \big(0, 2+\frac{4}{k(k-1)}\big] \cup \big[k-2, +\infty\big)$ for the $k$-user mimo y channel; ii) $\frac{n}{m} \in \big(0, 2+\frac{4}{k}\big] \cup \big[k-2, +\infty\big)$ for the multi-pair mimo two-way relay channel; iii) $\frac{n}{m} \in \big(0, 2+\frac{8}{k^2}\big] \cup \big[k-2, +\infty\big)$ for the generalized mimo two-way x relay channel. we also provide the antenna configuration regions for the general multi-user mimo two-way relay channel to achieve the total dof $km$.",10.1109/tit.2015.2420100,5/4/2014,4/2/2015,"['liu', 'tao']",['cs']
95,10,1004.4939999999999,fauxcrypt - a method of text obfuscation,['cs.cr'],"warnings have been raised about the steady diminution of privacy. more and more personal information, such as that contained electronic mail, is moving to cloud computing servers where it might be machine-searched and indexed. fauxcrypt is an algorithm for modification of a plaintext document that leaves it generally readable by a person but not readily searched or indexed by machine. the algorithm employs a dictionary substitution of selected words, and an obfuscating transposition of letters in other words. the obfuscation is designed to leave the words understandable, although they are badly spelled. fauxcrypt is free, open source software, with source code available.",,4/27/2010,2/12/2018,['gualtieri'],['math']
96,75,1404.3368,near-optimal sample compression for nearest neighbors,"['cs.lg', 'cs.cc']","we present the first sample compression algorithm for nearest neighbors with non-trivial performance guarantees. we complement these guarantees by demonstrating almost matching hardness lower bounds, which show that our bound is nearly optimal. our result yields new insight into margin-based nearest neighbor classification in metric spaces and allows us to significantly sharpen and simplify existing bounds. some encouraging empirical results are also presented.",,4/13/2014,3/26/2018,"['gottlieb', 'kontorovich', 'nisnevitch']",['cs']
97,54,1312.3748,on eavesdropper-tolerance capability of two-hop wireless networks,"['cs.it', 'math.it']","two-hop wireless network serves as the basic net-work model for the study of general wireless networks, while cooperative jamming is a promising scheme to achieve the physi-cal layer security. this paper establishes a theoretical framework for the study of eavesdropper-tolerance capability (i.e., the exact maximum number of eavesdroppers that can be tolerated) in a two-hop wireless network, where the cooperative jamming is adopted to ensure security defined by secrecy outage probability (sop) and opportunistic relaying is adopted to guarantee relia-bility defined by transmission outage probability (top). for the concerned network, closed form modeling for both sop and top is first conducted based on the central limit theorem. with the help of sop and top models and also the stochastic ordering theory, the model for eavesdropper-tolerance capability analysis is then developed. finally, extensive simulation and numerical results are provided to illustrate the efficiency of our theoretical framework as well as the eavesdropper-tolerance capability of the concerned network from adopting cooperative jamming and opportunistic relaying.",10.1109/tsc.2015.2478453,12/13/2013,,"['zhang', 'shen', 'wang', 'jiang']",['math']
98,97,1409.3954,mimo-mc radar: a mimo radar approach based on matrix completion,"['cs.it', 'math.it', 'stat.ap']","in a typical mimo radar scenario, transmit nodes transmit orthogonal waveforms, while each receive node performs matched filtering with the known set of transmit waveforms, and forwards the results to the fusion center. based on the data it receives from multiple antennas, the fusion center formulates a matrix, which, in conjunction with standard array processing schemes, such as music, leads to target detection and parameter estimation. in mimo radars with compressive sensing (mimo-cs), the data matrix is formulated by each receive node forwarding a small number of compressively obtained samples. in this paper, it is shown that under certain conditions, in both sampling cases, the data matrix at the fusion center is low-rank, and thus can be recovered based on knowledge of a small subset of its entries via matrix completion (mc) techniques. leveraging the low-rank property of that matrix, we propose a new mimo radar approach, termed, mimo-mc radar, in which each receive node either performs matched filtering with a small number of randomly selected dictionary waveforms or obtains sub-nyquist samples of the received signal at random sampling instants, and forwards the results to a fusion center. based on the received samples, and with knowledge of the sampling scheme, the fusion center partially fills the data matrix and subsequently applies mc techniques to estimate the full matrix. mimo-mc radars share the advantages of the recently proposed mimo-cs radars, i.e., high resolution with reduced amounts of data, but unlike mimo-cs radars do not require grid discretization. the mimo-mc radar concept is illustrated through a linear uniform array configuration, and its target estimation performance is demonstrated via simulations.",10.1109/taes.2015.140452,9/13/2014,,"['sun', 'bajwa', 'petropulu']",['cs']
99,39,1306.2595,capacity scaling in mimo systems with general unitarily invariant random   matrices,"['cs.it', 'math.it']","we investigate the capacity scaling of mimo systems with the system dimensions. to that end, we quantify how the mutual information varies when the number of antennas (at either the receiver or transmitter side) is altered. for a system comprising $r$ receive and $t$ transmit antennas with $r>t$, we find the following: by removing as many receive antennas as needed to obtain a square system (provided the channel matrices before and after the removal have full rank) the maximum resulting loss of mutual information over all signal-to-noise ratios (snrs) depends only on $r$, $t$ and the matrix of left-singular vectors of the initial channel matrix, but not on its singular values. in particular, if the latter matrix is haar distributed the ergodic rate loss is given by $\sum_{t=1}^{t}\sum_{r=t+1}^{r}\frac{1}{r-t}$ nats. under the same assumption, if $t,r\to \infty$ with the ratio $\phi\triangleq t/r$ fixed, the rate loss normalized by $r$ converges almost surely to $h(\phi)$ bits with $h(\cdot)$ denoting the binary entropy function. we also quantify and study how the mutual information as a function of the system dimensions deviates from the traditionally assumed linear growth in the minimum of the system dimensions at high snr.",,6/11/2013,3/5/2018,"['çakmak', 'müller', 'fleury']",['cs']
