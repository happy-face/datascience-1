,Unnamed: 0,id,title,subcategories,abstract,doi,created,updated,authors,main_categories
0,54,1504.05891,exponent function for one helper source coding problem at rates outside   the rate region,"['cs.it', 'math.it']","we consider the one helper source coding problem posed and investigated by ahlswede, k\""orner and wyner. in this system, the error probability of decoding goes to one as the source block length $n$ goes to infinity. this implies that we have a strong converse theorem for the one helper source coding problem. in this paper we provide a much stronger version of this strong converse theorem for the one helper source coding problem. we prove that the error probability of decoding tends to one exponentially and derive an explicit lower bound of this exponent function.",,4/22/2015,1/17/2019,['oohama'],"['cs', 'math']"
1,90,1602.07811,narrative smoothing: dynamic conversational network for the analysis of   tv series plots,"['cs.si', 'cs.mm']","modern popular tv series often develop complex storylines spanning several seasons, but are usually watched in quite a discontinuous way. as a result, the viewer generally needs a comprehensive summary of the previous season plot before the new one starts. the generation of such summaries requires first to identify and characterize the dynamics of the series subplots. one way of doing so is to study the underlying social network of interactions between the characters involved in the narrative. the standard tools used in the social networks analysis field to extract such a network rely on an integration of time, either over the whole considered period, or as a sequence of several time-slices. however, they turn out to be inappropriate in the case of tv series, due to the fact the scenes showed onscreen alternatively focus on parallel storylines, and do not necessarily respect a traditional chronology. this makes existing extraction methods inefficient to describe the dynamics of relationships between characters, or to get a relevant instantaneous view of the current social state in the plot. this is especially true for characters shown as interacting with each other at some previous point in the plot but temporarily neglected by the narrative. in this article, we introduce narrative smoothing, a novel, still exploratory, network extraction method. it smooths the relationship dynamics based on the plot properties, aiming at solving some of the limitations present in the standard approaches. in order to assess our method, we apply it to a new corpus of 3 popular tv series, and compare it to both standard approaches. our results are promising, showing narrative smoothing leads to more relevant observations when it comes to the characterization of the protagonists and their relationships. it could be used as a basis for further modeling the intertwined storylines constituting tv series plots.",10.1109/asonam.2016.7752379,2/25/2016,12/29/2018,"['bost', 'labatut', 'gueye', 'linarès']",['cs']
2,5,1006.0469,certifiably pseudorandom financial derivatives,"['q-fin.cp', 'cs.cc']","arora, barak, brunnermeier, and ge showed that taking computational complexity into account, a dishonest seller could strategically place lemons in financial derivatives to make them substantially less valuable to buyers. we show that if the seller is required to construct derivatives of a certain form, then this phenomenon disappears. in particular, we define and construct pseudorandom derivative families, for which lemon placement only slightly affects the values of the derivatives. our constructions use expander graphs. we study our derivatives in a more general setting than arora et al. in particular, we analyze arbitrary tranches of the common collateralized debt obligations (cdos) when the underlying assets can have significant dependencies.",,6/2/2010,1/27/2019,['zuckerman'],"['cs', 'q-fin']"
3,50,1503.00102,carp: context-aware reliability prediction of black-box web services,['cs.se'],"reliability prediction is an important task in software reliability engineering, which has been widely studied in the last decades. however, modelling and predicting user-perceived reliability of black-box services remain an open research problem. software services, such as web services and web apis, generally provide black-box functionalities to users through the internet, thus leading to a lack of their internal information for reliability analysis. furthermore, the user-perceived service reliability depends not only on the service itself, but also heavily on the invocation context (e.g., service workloads, network conditions), whereby traditional reliability models become ineffective and inappropriate. to address these new challenges posed by blackbox services, in this paper, we propose carp, a new contextaware reliability prediction approach, which leverages historical usage data from users to construct context-aware reliability models and further provides online reliability prediction results to users. through context-aware reliability modelling, carp is able to alleviate the data sparsity problem that heavily limits the prediction accuracy of other existing approaches. the preliminary evaluation results show that carp can make a significant improvement in reliability prediction accuracy, e.g., about 41% in mae and 38% in rmse when only 5% of the data are available.",,2/28/2015,12/30/2018,"['zhu', 'he', 'xie', 'zheng', 'lyu']",['cs']
4,91,1603.01739,grading of mammalian cumulus oocyte complexes using machine learning for   in vitro embryo culture,"['cs.cv', 'eess.iv', 'physics.med-ph']","visual observation of cumulus oocyte complexes provides only limited information about its functional competence, whereas the molecular evaluations methods are cumbersome or costly. image analysis of mammalian oocytes can provide attractive alternative to address this challenge. however, it is complex, given the huge number of oocytes under inspection and the subjective nature of the features inspected for identification. supervised machine learning methods like random forest with annotations from expert biologists can make the analysis task standardized and reduces inter-subject variability. we present a semi-automatic framework for predicting the class an oocyte belongs to, based on multi-object parametric segmentation on the acquired microscopic image followed by a feature based classification using random forests.",,3/5/2016,,"['sudarshan', 'weiser', 'chintala', 'mandal', 'dutta']","['cs', 'eess', 'physics']"
5,46,1501.02629,scaling-up empirical risk minimization: optimization of incomplete   u-statistics,"['stat.ml', 'cs.ai', 'cs.lg']","in a wide range of statistical learning problems such as ranking, clustering or metric learning among others, the risk is accurately estimated by $u$-statistics of degree $d\geq 1$, i.e. functionals of the training data with low variance that take the form of averages over $k$-tuples. from a computational perspective, the calculation of such statistics is highly expensive even for a moderate sample size $n$, as it requires averaging $o(n^d)$ terms. this makes learning procedures relying on the optimization of such data functionals hardly feasible in practice. it is the major goal of this paper to show that, strikingly, such empirical risks can be replaced by drastically computationally simpler monte-carlo estimates based on $o(n)$ terms only, usually referred to as incomplete $u$-statistics, without damaging the $o_{\mathbb{p}}(1/\sqrt{n})$ learning rate of empirical risk minimization (erm) procedures. for this purpose, we establish uniform deviation results describing the error made when approximating a $u$-process by its incomplete version under appropriate complexity assumptions. extensions to model selection, fast rate situations and various sampling techniques are also considered, as well as an application to stochastic gradient descent for erm. finally, numerical examples are displayed in order to provide strong empirical evidence that the approach we promote largely surpasses more naive subsampling techniques.",,1/12/2015,4/19/2016,"['clémençon', 'bellet', 'colin']","['cs', 'stat']"
6,85,1601.0122900000001,a comprehensive formal security analysis of oauth 2.0,['cs.cr'],"the oauth 2.0 protocol is one of the most widely deployed authorization/single sign-on (sso) protocols and also serves as the foundation for the new sso standard openid connect. despite the popularity of oauth, so far analysis efforts were mostly targeted at finding bugs in specific implementations and were based on formal models which abstract from many web features or did not provide a formal treatment at all.   in this paper, we carry out the first extensive formal analysis of the oauth 2.0 standard in an expressive web model. our analysis aims at establishing strong authorization, authentication, and session integrity guarantees, for which we provide formal definitions. in our formal analysis, all four oauth grant types (authorization code grant, implicit grant, resource owner password credentials grant, and the client credentials grant) are covered. they may even run simultaneously in the same and different relying parties and identity providers, where malicious relying parties, identity providers, and browsers are considered as well. our modeling and analysis of the oauth 2.0 standard assumes that security recommendations and best practices are followed, in order to avoid obvious and known attacks.   when proving the security of oauth in our model, we discovered four attacks which break the security of oauth. the vulnerabilities can be exploited in practice and are present also in openid connect.   we propose fixes for the identified vulnerabilities, and then, for the first time, actually prove the security of oauth in an expressive web model. in particular, we show that the fixed version of oauth (with security recommendations and best practices in place) provides the authorization, authentication, and session integrity properties we specify.",,1/6/2016,8/8/2016,"['fett', 'kuesters', 'schmitz']",['cs']
7,57,1505.03924,$k$-center clustering under perturbation resilience,"['cs.ds', 'cs.lg']","the $k$-center problem is a canonical and long-studied facility location and clustering problem with many applications in both its symmetric and asymmetric forms. both versions of the problem have tight approximation factors on worst case instances. therefore to improve on these ratios, one must go beyond the worst case.   in this work, we take this approach and provide strong positive results both for the asymmetric and symmetric $k$-center problems under a natural input stability (promise) condition called $\alpha$-perturbation resilience [bilu and linia 2012], which states that the optimal solution does not change under any alpha-factor perturbation to the input distances. we provide algorithms that give strong guarantees simultaneously for stable and non-stable instances: our algorithms always inherit the worst-case guarantees of clustering approximation algorithms, and output the optimal solution if the input is $2$-perturbation resilient. furthermore, we prove our result is tight by showing symmetric $k$-center under $(2-\epsilon)$-perturbation resilience is hard unless $np=rp$.   the impact of our results are multifaceted. this is the first tight result for any problem under perturbation resilience. furthermore, our results illustrate a surprising relationship between symmetric and asymmetric $k$-center instances under perturbation resilience. unlike approximation ratio, for which symmetric $k$-center is easily solved to a factor of 2 but asymmetric $k$-center cannot be approximated to any constant factor, both symmetric and asymmetric $k$-center can be solved optimally under resilience to 2-perturbations. finally, our guarantees in the setting where only part of the data satisfies perturbation resilience makes these algorithms more applicable to real-life instances.",,5/14/2015,12/28/2018,"['balcan', 'haghtalab', 'white']",['cs']
8,75,1510.0823300000002,a fast randomized method to find homotopy classes for socially-aware   navigation,"['cs.ro', 'cs.cv']","we introduce and show preliminary results of a fast randomized method that finds a set of k paths lying in distinct homotopy classes. we frame the path planning task as a graph search problem, where the navigation graph is based on a voronoi diagram. the search is biased by a cost function derived from the social force model that is used to generate and select the paths. we compare our method to yen's algorithm, and empirically show that our approach is faster to find a subset of homotopy classes. furthermore our approach computes a set of more diverse paths with respect to the baseline while obtaining a negligible loss in path quality.",,10/28/2015,,"['palmieri', 'rudenko', 'arras']",['cs']
9,55,1504.06045,coordinated spatial pattern formation in biomolecular communication   networks,"['q-bio.mn', 'cs.sy', 'nlin.ps']","this paper proposes a control theoretic framework to model and analyze the self-organized pattern formation of molecular concentrations in biomolecular communication networks, emerging applications in synthetic biology. in biomolecular communication networks, bionanomachines, or biological cells, communicate with each other using a cell-to-cell communication mechanism mediated by a diffusible signaling molecule, thereby the dynamics of molecular concentrations are approximately modeled as a reaction-diffusion system with a single diffuser. we first introduce a feedback model representation of the reaction-diffusion system and provide a systematic local stability/instability analysis tool using the root locus of the feedback system. the instability analysis then allows us to analytically derive the conditions for the self-organized spatial pattern formation, or turing pattern formation, of the bionanomachines. we propose a novel synthetic biocircuit motif called activator-repressor-diffuser system and show that it is one of the minimum biomolecular circuits that admit self-organized patterns over cell population.",10.1109/tmbmc.2015.2500567,4/23/2015,1/5/2019,"['hori', 'miyazako', 'kumagai', 'hara']","['cs', 'q-bio', 'physics']"
10,88,1601.07414,location games on networks: existence and efficiency of equilibria,"['cs.gt', 'math.oc']","we consider a game where a finite number of retailers choose a location, given that their potential consumers are distributed on a network. retailers do not compete on price but only on location, therefore each consumer shops at the closest store. we show that when the number of retailers is large enough, the game admits a pure nash equilibrium and we construct it. we then compare the equilibrium cost borne by the consumers with the cost that could be achieved if the retailers followed the dictate of a benevolent planner. we perform this comparison in term of the price of anarchy, i.e., the ratio of the worst equilibrium cost and the optimal cost, and the price of stability, i.e., the ratio of the best equilibrium cost and the optimal cost. we show that, asymptotically in the number of retailers, these ratios are bounded by two and one, respectively.",10.1287/moor.2017.0921,1/27/2016,4/1/2017,"['fournier', 'scarsini']","['cs', 'math']"
11,68,1507.07909,offline handwritten signature verification - literature review,"['cs.cv', 'stat.ml']","the area of handwritten signature verification has been broadly researched in the last decades, but remains an open research problem. the objective of signature verification systems is to discriminate if a given signature is genuine (produced by the claimed individual), or a forgery (produced by an impostor). this has demonstrated to be a challenging task, in particular in the offline (static) scenario, that uses images of scanned signatures, where the dynamic information about the signing process is not available. many advancements have been proposed in the literature in the last 5-10 years, most notably the application of deep learning methods to learn feature representations from signature images. in this paper, we present how the problem has been handled in the past few decades, analyze the recent advancements in the field, and the potential directions for future research.",10.1109/ipta.2017.8310112,7/28/2015,10/16/2017,"['hafemann', 'sabourin', 'oliveira']","['cs', 'stat']"
12,96,1604.00635,quantum-inspired secure wireless communication protocol under spatial   and local gaussian noise assumptions,"['cs.it', 'math.it']","inspired from quantum key distribution, we consider wireless communication between alice and bob when the intermediate space between alice and bob is controlled by eve. that is, our model divides the channel noise into two parts, the noise generated during the transmission and the noise generated in the detector. eve is allowed to control the former, but is not allowed to do the latter. while the latter is assumed to be a gaussian random variable, the former is not assumed to be a gaussian random variable. in this situation, using backward reconciliation and the random sampling, we propose a protocol to generate secure keys between alice and bob under the assumption that eve's detector has a gaussian noise and eve is out of alice's neighborhood. in our protocol, the security criteria are quantitatively guaranteed even with finite block-length code based on the evaluation of error of the estimation of channel.",,4/3/2016,12/30/2018,['hayashi'],"['cs', 'math']"
13,28,1404.5943,price of anarchy for auction revenue,['cs.gt'],"this paper develops tools for welfare and revenue analyses of bayes-nash equilibria in asymmetric auctions with single-dimensional agents. we employ these tools to derive price of anarchy results for social welfare and revenue. our approach separates the standard smoothness framework into two distinct parts, isolating the analysis common to any auction from the analysis specific to a given auction. the first part relates a bidder's contribution to welfare in equilibrium to their contribution to welfare in the optimal auction using the price the bidder faces for additional allocation. intuitively, either an agent's utility and hence contribution to welfare is high, or the price she has to pay for additional allocation is high relative to her value. we call this condition value covering; it holds in every bayes-nash equilibrium of any auction. the second part, revenue covering, relates the prices bidders face for additional allocation to the revenue of the auction, using an auction's rules and feasibility constraints. combining the two parts gives approximation results to the optimal welfare, and, under the right conditions, the optimal revenue. in mechanisms with reserve prices, our welfare results show approximation with respect to the optimal mechanism with the same reserves.   as a center-piece result, we analyze the single-item first-price auction with individual monopoly reserves. when each distribution satisfies a regularity condition the auction's revenue is at least a $2e/(e-1) \approx 3.16$ approximation to the revenue of the optimal auction. we also give bounds for matroid auctions with first-price or all-pay semantics, and the generalized first-price position auction. finally, we give an extension theorem for simultaneous composition, i.e., when multiple auctions are run simultaneously, with single-valued, unit-demand agents.",,4/23/2014,1/16/2019,"['hartline', 'hoy', 'taggart']",['cs']
14,76,1511.00615,optimizing the deployment of electric vehicle charging stations using   pervasive mobility data,"['cs.sy', 'cs.si']","with recent advances in battery technology and the resulting decrease in the charging times, public charging stations are becoming a viable option for electric vehicle (ev) drivers. concurrently, wide-spread use of location-tracking devices in mobile phones and wearable devices makes it possible to track individual-level human movements to an unprecedented spatial and temporal grain. motivated by these developments, we propose a novel methodology to perform data-driven optimization of ev charging stations location. we formulate the problem as a discrete optimization problem on a geographical grid, with the objective of covering the entire demand region while minimizing a measure of drivers' discomfort. since optimally solving the problem is computationally infeasible, we present computationally efficient, near-optimal solutions based on greedy and genetic algorithms. we then apply the proposed methodology to optimize ev charging stations location in the city of boston, starting from a massive cellular phone data sets covering 1 million users over 4 months. results show that genetic algorithm based optimization provides the best solutions in terms of drivers' discomfort and the number of charging stations required, which are both reduced about 10 percent as compared to a randomized solution. we further investigate robustness of the proposed data-driven methodology, showing that, building upon well-known regularity of aggregate human mobility patterns, the near-optimal solution computed using single day movements preserves its properties also in later months. when collectively considered, the results presented in this paper clearly indicate the potential of data-driven approaches for optimally locating public charging facilities at the urban scale.",10.1016/j.tra.2019.01.002,11/2/2015,,"['vazifeh', 'zhang', 'santi', 'ratti']",['cs']
15,20,1308.4452,a new statement for selection and exception handling in imperative   languages,['cs.pl'],"diverse selection statements -- if-then-else, switch and try-catch -- are commonly used in modern programming languages. to make things simple, we propose a unifying statement for selection. this statement is of the form seqor(g_1,...,g_n) where each $g_i$ is a statement. it has a a simple semantics: sequentially choose the first successful statement $g_i$ and then proceeds with executing $g_i$. examples will be provided for this statement.",,8/20/2013,1/11/2019,['kwon'],['cs']
16,12,1205.5788,a colonel blotto gladiator game,"['cs.gt', 'math.pr']","we consider a stochastic version of the well-known blotto game, called the gladiator game. in this zero-sum allocation game two teams of gladiators engage in a sequence of one-to-one fights in which the probability of winning is a function of the gladiators' strengths. each team's strategy consists of the allocation of its total strength among its gladiators. we find the nash equilibria and the value of this class of games and show how they depend on the total strength of teams and the number of gladiators in each team. to do this, we study interesting majorization-type probability inequalities concerning linear combinations of gamma random variables. similar inequalities have been used in models of telecommunications and research and development.",10.1287/moor.1120.0550,3/27/2012,,"['rinott', 'scarsini', 'yu']","['cs', 'math']"
17,72,1508.05515,"approximation algorithm for minimum weight $(k,m)$-cds problem in unit   disk graph","['cs.dm', 'cs.ds']","in a wireless sensor network, the virtual backbone plays an important role. due to accidental damage or energy depletion, it is desirable that the virtual backbone is fault-tolerant. a fault-tolerant virtual backbone can be modeled as a $k$-connected $m$-fold dominating set ($(k,m)$-cds for short). in this paper, we present a constant approximation algorithm for the minimum weight $(k,m)$-cds problem in unit disk graphs under the assumption that $k$ and $m$ are two fixed constants with $m\geq k$. prior to this work, constant approximation algorithms are known for $k=1$ with weight and $2\leq k\leq 3$ without weight. our result is the first constant approximation algorithm for the $(k,m)$-cds problem with general $k,m$ and with weight. the performance ratio is $(\alpha+2.5k\rho)$ for $k\geq 3$ and $(\alpha+2.5\rho)$ for $k=2$, where $\alpha$ is the performance ratio for the minimum weight $m$-fold dominating set problem and $\rho$ is the performance ratio for the subset $k$-connected subgraph problem (both problems are known to have constant performance ratios.)",10.1109/tnet.2016.2607723,8/22/2015,1/4/2019,"['shi', 'zhang', 'du']",['cs']
18,17,1307.3648,verifying time complexity of deterministic turing machines,"['cs.lo', 'cs.cc', 'cs.fl']","we show that, for all reasonable functions $t(n)=o(n\log n)$, we can algorithmically verify whether a given one-tape turing machine runs in time at most $t(n)$. this is a tight bound on the order of growth for the function $t$ because we prove that, for $t(n)\geq(n+1)$ and $t(n)=\omega(n\log n)$, there exists no algorithm that would verify whether a given one-tape turing machine runs in time at most $t(n)$.   we give results also for the case of multi-tape turing machines. we show that we can verify whether a given multi-tape turing machine runs in time at most $t(n)$ iff $t(n_0)< (n_0+1)$ for some $n_0\in\mathbb{n}$.   we prove a very general undecidability result stating that, for any class of functions $\mathcal{f}$ that contains arbitrary large constants, we cannot verify whether a given turing machine runs in time $t(n)$ for some $t\in\mathcal{f}$. in particular, we cannot verify whether a turing machine runs in constant, polynomial or exponential time.",10.1016/j.tcs.2015.07.028,7/13/2013,5/19/2014,['gajser'],['cs']
19,51,1503.02521,a single-pass classifier for categorical data,['cs.ai'],"this paper describes a new method for classifying a dataset that partitions elements into their categories. it has relations with neural networks but a slightly different structure, requiring only a single pass through the classifier to generate the weight sets. a grid-like structure is required as part of a novel idea of converting a 1-d row of real values into a 2-d structure of value bands. each cell in any band then stores a distinct set of weights, to represent its own importance and its relation to each output category. during classification, all of the output weight lists can be retrieved and summed to produce a probability for what the correct output category is. the bands possibly work like hidden layers of neurons, but they are variable specific, making the process orthogonal. the construction process can be a single update process without iterations, making it potentially much faster. it can also be compared with k-nn and may be practical for partial or competitive updating.",,3/9/2015,6/29/2016,['greer'],['cs']
20,13,1206.6476,similarity learning for provably accurate sparse linear classification,"['cs.lg', 'cs.ai', 'stat.ml']","in recent years, the crucial importance of metrics in machine learning algorithms has led to an increasing interest for optimizing distance and similarity functions. most of the state of the art focus on learning mahalanobis distances (requiring to fulfill a constraint of positive semi-definiteness) for use in a local k-nn algorithm. however, no theoretical link is established between the learned metrics and their performance in classification. in this paper, we make use of the formal framework of good similarities introduced by balcan et al. to design an algorithm for learning a non psd linear similarity optimized in a nonlinear feature space, which is then used to build a global linear classifier. we show that our approach has uniform stability and derive a generalization bound on the classification error. experiments performed on various datasets confirm the effectiveness of our approach compared to state-of-the-art methods and provide evidence that (i) it is fast, (ii) robust to overfitting and (iii) produces very sparse classifiers.",,6/27/2012,,"['bellet', 'habrard', 'sebban']","['cs', 'stat']"
21,64,1506.03124,multiscale edge detection and parametric shape modeling for boundary   delineation in optoacoustic images,"['physics.med-ph', 'cs.cv', 'eess.iv']","in this article, we present a novel scheme for segmenting the image boundary (with the background) in optoacoustic small animal in vivo imaging systems. the method utilizes a multiscale edge detection algorithm to generate a binary edge map. a scale dependent morphological operation is employed to clean spurious edges. thereafter, an ellipse is fitted to the edge map through constrained parametric transformations and iterative goodness of fit calculations. the method delimits the tissue edges through the curve fitting model, which has shown high levels of accuracy. thus, this method enables segmentation of optoacoutic images with minimal human intervention, by eliminating need of scale selection for multiscale processing and seed point determination for contour mapping.",10.1109/embc.2015.7318460,6/9/2015,,"['mandal', 'sudarshan', 'nagaraj', 'ben', 'razansky']","['cs', 'eess', 'physics']"
22,65,1506.0749,discrete gaussian sampling reduces to cvp and svp,"['cs.cc', 'cs.ds']","the discrete gaussian $d_{l- t, s}$ is the distribution that assigns to each vector $x$ in a shifted lattice $l - t$ probability proportional to $e^{-\pi \|x\|^2/s^2}$. it has long been an important tool in the study of lattices. more recently, algorithms for discrete gaussian sampling (dgs) have found many applications in computer science. in particular, polynomial-time algorithms for dgs with very high parameters $s$ have found many uses in cryptography and in reductions between lattice problems. and, in the past year, aggarwal, dadush, regev, and stephens-davidowitz showed $2^{n+o(n)}$-time algorithms for dgs with a much wider range of parameters and used them to obtain the current fastest known algorithms for the two most important lattice problems, the shortest vector problem (svp) and the closest vector problem (cvp).   motivated by its increasing importance, we investigate the complexity of dgs itself and its relationship to cvp and svp. our first result is a polynomial-time dimension-preserving reduction from dgs to cvp. there is a simple reduction from cvp to dgs, so this shows that dgs is equivalent to cvp. our second result, which we find to be more surprising, is a polynomial-time dimension-preserving reduction from centered dgs (the important special case when $ t = 0$) to svp. in the other direction, there is a simple reduction from $\gamma$-approximate svp for any $\gamma = \omega(\sqrt{n/\log n})$, and we present some (relatively weak) evidence to suggest that this might be the best achievable approximation factor.   we also show that our cvp result extends to a much wider class of distributions and even to other norms.",,6/24/2015,4/19/2016,['stephens-davidowitz'],['cs']
23,11,1205.1227,are e-readers suitable tools for scholarly work?,"['cs.dl', 'cs.hc']","this paper aims to offer insights into the usability, acceptance and limitations of e-readers with regard to the specific requirements of scholarly text work. to fit into the academic workflow non-linear reading, bookmarking, commenting, extracting text or the integration of non-textual elements must be supported. a group of social science students were questioned about their experiences with electronic publications for study purposes. this same group executed several text-related tasks with the digitized material presented to them in two different file formats on four different e-readers. their performances were subsequently evaluated by means of frequency analyses in detail. findings - e-publications have made advances in the academic world; however e-readers do not yet fit seamlessly into the established chain of scholarly text-processing focusing on how readers use material during and after reading. our tests revealed major deficiencies in these techniques. with a small number of participants (n=26) qualitative insights can be obtained, not representative results. further testing with participants from various disciplines and of varying academic status is required to arrive at more broadly applicable results. practical implications - our test results help to optimize file conversion routines for scholarly texts. we evaluated our data on the basis of descriptive statistics and abstained from any statistical significance test. the usability test of e-readers in a scientific context aligns with both studies on the prevalence of e-books in the sciences and technical test reports of portable reading devices. still, it takes a distinctive angle in focusing on the characteristics and procedures of textual work in the social sciences and measures the usability of e-readers and file-features against these standards.",10.1108/oir-12-2011-0221,5/6/2012,,"['schomisch', 'zens', 'mayr']",['cs']
24,15,1209.585,thesoz: a skos representation of the thesaurus for the social sciences,['cs.dl'],"the thesaurus for the social sciences (thesoz) is a linked dataset in skos format, which serves as a crucial instrument for information retrieval based on e.g. document indexing or search term recommendation. thesauri and similar controlled vocabularies build a linking bridge for other datasets from the linked open data cloud - even between different domains. the information and knowledge, which is exposed by such links, can be processed by semantic web applications. in this article the conversion process of the thesoz to skos is described including the analysis of the original dataset and its structure, the mapping to adequate skos classes and properties, and the technical conversion. furthermore mappings to other datasets and the appliance of the thesoz are presented. finally, limitations and modeling issues encountered during the creation process are discussed.",10.3233/sw-2012-0081,9/26/2012,,"['zapilko', 'schaible', 'mayr', 'mathiak']",['cs']
25,84,1512.0413800000001,search-to-decision reductions for lattice problems with approximation   factors (slightly) greater than one,"['cs.cc', 'cs.ds']","we show the first dimension-preserving search-to-decision reductions for approximate svp and cvp. in particular, for any $\gamma \leq 1 + o(\log n/n)$, we obtain an efficient dimension-preserving reduction from $\gamma^{o(n/\log n)}$-svp to $\gamma$-gapsvp and an efficient dimension-preserving reduction from $\gamma^{o(n)}$-cvp to $\gamma$-gapcvp. these results generalize the known equivalences of the search and decision versions of these problems in the exact case when $\gamma = 1$. for svp, we actually obtain something slightly stronger than a search-to-decision reduction---we reduce $\gamma^{o(n/\log n)}$-svp to $\gamma$-unique svp, a potentially easier problem than $\gamma$-gapsvp.",,12/13/2015,4/23/2017,['stephens-davidowitz'],['cs']
26,14,1209.1086,robustness and generalization for metric learning,"['cs.lg', 'cs.ai', 'stat.ml']","metric learning has attracted a lot of interest over the last decade, but the generalization ability of such methods has not been thoroughly studied. in this paper, we introduce an adaptation of the notion of algorithmic robustness (previously introduced by xu and mannor) that can be used to derive generalization bounds for metric learning. we further show that a weak notion of robustness is in fact a necessary and sufficient condition for a metric learning algorithm to generalize. to illustrate the applicability of the proposed framework, we derive generalization results for a large family of existing metric learning algorithms, including some sparse formulations that are not covered by previous results.",10.1016/j.neucom.2014.09.044,9/5/2012,9/29/2014,"['bellet', 'habrard']","['cs', 'stat']"
27,30,1407.2991,price of anarchy with heterogeneous latency functions,['cs.gt'],"in this paper we consider the price of anarchy (poa) in multi-commodity flows where the latency or delay function on an edge has a heterogeneous dependency on the flow commodities, i.e. when the delay on each link is dependent on the flow of individual commodities, rather than on the aggregate flow. an application of this study is the performance analysis of a network with differentiated traffic that may arise when traffic is prioritized according to some type classification. this study has implications in the debate on net-neutrality. we provide price of anarchy bounds for networks with $k$ (types of) commodities where each link is associated with heterogeneous polynomial delays, i.e. commodity $i$ on edge $e$ faces delay specified by $g_{i1}(e)f^{\theta}_1(e) + g_{i2}(e)f^{\theta}_2(e) + \ldots + g_{ik}(e)f^{\theta}_k(e) + c_i(e), $ where $f_i(e)$ is the flow of the $i$th commodity through edge $e$, $\theta \in {\cal n}$, $g_{i1}(e), g_{i2}(e), \ldots, g_{ik}(e)$ and $c_i(e)$ are nonnegative constants. we consider both atomic and non-atomic flows.   for networks with decomposable delay functions where the delay induced by a particular commodity is the same, i.e. delays on edge $e$ are defined by $a_1(e)f_1^\theta(e) + a_2(e)f_2^\theta(e) + \ldots + c(e)$ where $\forall j , \forall e: g_{1j}(e) = g_{2j}(e) = \ldots = a_j(e)$, we show an improved bound on the price of anarchy.   further, we show bounds on the price of anarchy for uniform latency functions where each edge of the network has the same delay function.",,7/10/2014,12/31/2018,"['kapoor', 'shin']",['cs']
28,98,1604.05676,"scientific computing, high-performance computing and data science in   higher education","['cs.cy', 'cs.dc']","we present an overview of current academic curricula for scientific computing, high-performance computing and data science. after a survey of current academic and non-academic programs across the globe, we focus on canadian programs and specifically on the education program of the scinet hpc consortium, using its detailed enrollment and course statistics for the past four to five years. not only do these data display a steady and rapid increase in the demand for research-computing instruction, they also show a clear shift from traditional (high performance) computing to data-oriented methods. it is argued that this growing demand warrants specialized research computing degrees. the possible curricula of such degrees are described next, taking existing programs as an example, and adding scinet's experiences of student desires as well as trends in advanced research computing.",10.22369/issn.2153-4136/10/1/5,4/19/2016,6/16/2016,"['ponce', 'spence', 'gruner', 'van zon']",['cs']
29,52,1503.04333,a more human way to play computer chess,['cs.ai'],"this paper suggests a forward-pruning technique for computer chess that uses 'move tables', which are like transposition tables, but for moves not positions. they use an efficient memory structure and has put the design into the context of long and short-term memories. the long-term memory updates a play path with weight reinforcement, while the short-term memory can be immediately added or removed. with this, 'long branches' can play a short path, before returning to a full search at the resulting leaf nodes. re-using an earlier search path allows the tree to be forward-pruned, which is known to be dangerous, because it removes part of the search process. additional checks are therefore made and moves can even be re-added when the search result is unsatisfactory. automatic feature analysis is now central to the algorithm, where key squares and related squares can be generated automatically and used to guide the search process. using this analysis, if a search result is inferior, it can re-insert un-played moves that cover these key squares only. on the tactical side, a type of move that the forward-pruning will fail on is recognised and a pattern-based solution to that problem is suggested. this has completed the theory of an earlier paper and resulted in a more human-like approach to searching for a chess move. tests demonstrate that the obvious blunders associated with forward pruning are no longer present and that it can compete at the top level with regard to playing strength.",,3/14/2015,1/17/2019,['greer'],['cs']
30,8,1112.1937,bootstrapping intrinsically motivated learning with human demonstrations,"['cs.lg', 'cs.ai', 'cs.ro']","this paper studies the coupling of internally guided learning and social interaction, and more specifically the improvement owing to demonstrations of the learning by intrinsic motivation. we present socially guided intrinsic motivation by demonstration (sgim-d), an algorithm for learning in continuous, unbounded and non-preset environments. after introducing social learning and intrinsic motivation, we describe the design of our algorithm, before showing through a fishing experiment that sgim-d efficiently combines the advantages of social learning and intrinsic motivation to gain a wide repertoire while being specialised in specific subspaces.",10.1109/devlrn.2011.6037329,12/8/2011,,"['nguyen', 'baranes', 'oudeyer']",['cs']
31,31,1407.6756,higher lower bounds from the 3sum conjecture,['cs.ds'],"the 3sum conjecture has proven to be a valuable tool for proving conditional lower bounds on dynamic data structures and graph problems. this line of work was initiated by p\v{a}tra\c{s}cu (stoc 2010) who reduced 3sum to an offline setdisjointness problem. however, the reduction introduced by p\v{a}tra\c{s}cu suffers from several inefficiencies, making it difficult to obtain tight conditional lower bounds from the 3sum conjecture.   in this paper we address many of the deficiencies of p\v{a}tra\c{s}cu's framework. we give new and efficient reductions from 3sum to offline setdisjointness and offline setintersection (the reporting version of setdisjointness) which leads to polynomially higher lower bounds on several problems. using our reductions, we are able to show the essential optimality of several algorithms, assuming the 3sum conjecture.   - chiba and nishizeki's $o(m\alpha)$-time algorithm (sicomp 1985) for enumerating all triangles in a graph with arboricity/degeneracy $\alpha$ is essentially optimal, for any $\alpha$.   - bj{\o}rklund, pagh, williams, and zwick's algorithm (icalp 2014) for listing $t$ triangles is essentially optimal (assuming the matrix multiplication exponent is $\omega=2$).   - any static data structure for setdisjointness that answers queries in constant time must spend $\omega(n^{2-o(1)})$ time in preprocessing, where $n$ is the size of the set system.   these statements were unattainable via p\v{a}tra\c{s}cu's reductions.   we also introduce several new reductions from 3sum to pattern matching problems and dynamic graph problems. of particular interest are new conditional lower bounds for dynamic versions of maximum cardinality matching, which introduce a new technique for obtaining amortized lower bounds.",,7/24/2014,1/12/2019,"['kopelowitz', 'pettie', 'porat']",['cs']
32,59,1505.06582,implementing 64-bit maximally equidistributed $\mathbb{f}_2$-linear   generators with mersenne prime period,"['math.na', 'cs.na']","cpus and operating systems are moving from 32 to 64 bits, and hence it is important to have good pseudorandom number generators designed to fully exploit these word lengths. however, existing 64-bit very long period generators based on linear recurrences modulo 2 are not completely optimized in terms of the equidistribution properties. here we develop 64-bit maximally equidistributed pseudorandom number generators that are optimal in this respect and have speeds equivalent to 64-bit mersenne twisters. we provide a table of specific parameters with period lengths from $2^{607}-1$ to $2^{44497}-1$. (an online appendix is available at http://www.ritsumei.ac.jp/~harase/melg-64-app.pdf)",10.1145/3159444,5/25/2015,11/20/2017,"['harase', 'kimoto']","['cs', 'math']"
33,1,712.2449,reducing semantic complexity in distributed digital libraries: treatment   of term vagueness and document re-ranking,['cs.dl'],"the purpose of the paper is to propose models to reduce the semantic complexity in heterogeneous dls. the aim is to introduce value-added services (treatment of term vagueness and document re-ranking) that gain a certain quality in dls if they are combined with heterogeneity components established in the project ""competence center modeling and treatment of semantic heterogeneity"". empirical observations show that freely formulated user terms and terms from controlled vocabularies are often not the same or match just by coincidence. therefore, a value-added service will be developed which rephrases the natural language searcher terms into suggestions from the controlled vocabulary, the search term recommender (str). two methods, which are derived from scientometrics and network analysis, will be implemented with the objective to re-rank result sets by the following structural properties: the ranking of the results by core journals (so-called bradfordizing) and ranking by centrality of authors in co-authorship networks.",10.1108/00242530810865484,12/14/2007,,"['mayr', 'mutschke', 'petras']",['cs']
34,27,1404.4105,sparse compositional metric learning,"['cs.lg', 'cs.ai', 'stat.ml']","we propose a new approach for metric learning by framing it as learning a sparse combination of locally discriminative metrics that are inexpensive to generate from the training data. this flexible framework allows us to naturally derive formulations for global, multi-task and local metric learning. the resulting algorithms have several advantages over existing methods in the literature: a much smaller number of parameters to be estimated and a principled way to generalize learned metrics to new testing data points. to analyze the approach theoretically, we derive a generalization bound that justifies the sparse combination. empirically, we evaluate our algorithms on several datasets against state-of-the-art metric learning methods. the results are consistent with our theoretical findings and demonstrate the superiority of our approach in terms of classification performance and scalability.",,4/15/2014,,"['shi', 'bellet', 'sha']","['cs', 'stat']"
35,2,808.0518,building a terminology network for search: the komohe project,"['cs.dl', 'cs.db']","the paper reports about results on the gesis-iz project ""competence center modeling and treatment of semantic heterogeneity"" (komohe). komohe supervised a terminology mapping effort, in which 'cross-concordances' between major controlled vocabularies were organized, created and managed. in this paper we describe the establishment and implementation of cross-concordances for search in a digital library (dl).",10.18452/1264,8/4/2008,,"['mayr', 'petras']",['cs']
36,38,1411.2374,similarity learning for high-dimensional sparse data,"['cs.lg', 'cs.ai', 'stat.ml']","a good measure of similarity between data points is crucial to many tasks in machine learning. similarity and metric learning methods learn such measures automatically from data, but they do not scale well respect to the dimensionality of the data. in this paper, we propose a method that can learn efficiently similarity measure from high-dimensional sparse data. the core idea is to parameterize the similarity measure as a convex combination of rank-one matrices with specific sparsity structures. the parameters are then optimized with an approximate frank-wolfe procedure to maximally satisfy relative similarity constraints on the training data. our algorithm greedily incorporates one pair of features at a time into the similarity measure, providing an efficient way to control the number of active features and thus reduce overfitting. it enjoys very appealing convergence guarantees and its time and memory complexity depends on the sparsity of the data instead of the dimension of the feature space. our experiments on real-world high-dimensional datasets demonstrate its potential for classification, dimensionality reduction and data exploration.",,11/10/2014,10/21/2015,"['liu', 'bellet', 'sha']","['cs', 'stat']"
37,24,1403.1866,an expressive model for the web infrastructure: definition and   application to the browserid sso system,['cs.cr'],"the web constitutes a complex infrastructure and as demonstrated by numerous attacks, rigorous analysis of standards and web applications is indispensable.   inspired by successful prior work, in particular the work by akhawe et al. as well as bansal et al., in this work we propose a formal model for the web infrastructure. while unlike prior works, which aim at automatic analysis, our model so far is not directly amenable to automation, it is much more comprehensive and accurate with respect to the standards and specifications. as such, it can serve as a solid basis for the analysis of a broad range of standards and applications.   as a case study and another important contribution of our work, we use our model to carry out the first rigorous analysis of the browserid system (a.k.a. mozilla persona), a recently developed complex real-world single sign-on system that employs technologies such as ajax, cross-document messaging, and html5 web storage. our analysis revealed a number of very critical flaws that could not have been captured in prior models. we propose fixes for the flaws, formally state relevant security properties, and prove that the fixed system in a setting with a so-called secondary identity provider satisfies these security properties in our model. the fixes for the most critical flaws have already been adopted by mozilla and our findings have been rewarded by the mozilla security bug bounty program.",,3/7/2014,4/7/2014,"['fett', 'kuesters', 'schmitz']",['cs']
38,41,1411.721,analyzing the browserid sso system with primary identity providers using   an expressive model of the web,['cs.cr'],"browserid is a complex, real-world single sign-on (sso) system for web applications recently developed by mozilla. it employs new html5 features (such as web messaging and web storage) and cryptographic assertions to provide decentralized login, with the intent to respect users' privacy. it can operate in a primary and a secondary identity provider mode. while in the primary mode browserid runs with arbitrary identity providers (idps), in the secondary mode there is one idp only, namely mozilla's default idp.   we recently proposed an expressive general model for the web infrastructure and, based on this web model, analyzed the security of the secondary idp mode of browserid. the analysis revealed several severe vulnerabilities.   in this paper, we complement our prior work by analyzing the even more complex primary idp mode of browserid. we do not only study authentication properties as before, but also privacy properties. during our analysis we discovered new and practical attacks that do not apply to the secondary mode: an identity injection attack, which violates a central authentication property of sso systems, and attacks that break an important privacy promise of browserid and which do not seem to be fixable without a major redesign of the system. some of our attacks on privacy make use of a browser side channel that has not gained a lot of attention so far.   for the authentication bug, we propose a fix and formally prove in a slight extension of our general web model that the fixed system satisfies all the requirements we consider. this constitutes the most complex formal analysis of a web application based on an expressive model of the web infrastructure so far.   as another contribution, we identify and prove important security properties of generic web features in the extended web model to facilitate future analysis efforts of web standards and web applications.",,11/26/2014,4/1/2015,"['fett', 'kuesters', 'schmitz']",['cs']
39,47,1501.05775,an ${\cal o}(n^2 \log(n))$ algorithm for the weighted stable set problem   in claw-free graphs,['cs.dm'],"a graph $g(v, e)$ is \emph{claw-free} if no vertex has three pairwise non-adjacent neighbours. the maximum weight stable set (mwss) problem in a claw-free graph is a natural generalization of the matching problem and has been shown to be polynomially solvable by minty and sbihi in 1980. in a remarkable paper, faenza, oriolo and stauffer have shown that, in a two-step procedure, a claw-free graph can be first turned into a quasi-line graph by removing strips containing all the irregular nodes and then decomposed into \emph{\{claw, net\}-free} strips and strips with stability number at most three. through this decomposition, the mwss problem can be solved in ${\cal o}(|v|(|v| \log |v| + |e|))$ time. in this paper, we describe a direct decomposition of a claw-free graph into \emph{\{claw, net\}-free} strips and strips with stability number at most three which can be performed in ${\cal o}(|v|^2)$ time. in two companion papers we showed that the mwss problem can be solved in ${\cal o}(|e| \log |v|)$ time in claw-free graphs with $\alpha(g) \le 3$ and in ${\cal o}(|v| \sqrt{|e|})$ time in \{claw, net\}-free graphs with $\alpha(g) \ge 4$. these results prove that the mwss problem in a claw-free graph can be solved in ${\cal o}(|v|^2 \log |v|)$ time, the same complexity of the best and long standing algorithm for the mwss problem in \emph{line graphs}.",,1/23/2015,1/10/2019,"['nobili', 'sassano']",['cs']
40,87,1601.07216,security games in network flow problems,"['cs.gt', 'cs.sy']","this article considers a two-player strategic game for network routing under link disruptions. player 1 (defender) routes flow through a network to maximize her value of effective flow while facing transportation costs. player 2 (attacker) simultaneously disrupts one or more links to maximize her value of lost flow but also faces cost of disrupting links. linear programming duality in zero-sum games and the max-flow min-cut theorem are applied to obtain properties that are satisfied in any nash equilibrium. a characterization of the support of the equilibrium strategies is provided using graph-theoretic arguments. finally, conditions under which these results extend to budget-constrained environments are also studied. these results extend the classical minimum cost maximum flow problem and the minimum cut problem to a class of security games on flow networks.",,1/26/2016,1/21/2019,"['dahan', 'amin']",['cs']
41,34,1409.3182,ground state connectivity of local hamiltonians,"['quant-ph', 'cond-mat.str-el', 'cs.cc']","the study of ground state energies of local hamiltonians has played a fundamental role in quantum complexity theory. in this paper, we take a new direction by introducing the physically motivated notion of ""ground state connectivity"" of local hamiltonians, which captures problems in areas ranging from quantum stabilizer codes to quantum memories. roughly, ""ground state connectivity"" corresponds to the natural question: given two ground states |{\psi}> and |{\phi}> of a local hamiltonian h, is there an ""energy barrier"" (with respect to h) along any sequence of local operations mapping |{\psi}> to |{\phi}>? we show that the complexity of this question can range from qcma-complete to pspace-complete, as well as nexp-complete for an appropriately defined ""succinct"" version of the problem. as a result, we obtain a natural qcma-complete problem, a goal which has generally proven difficult since the conception of qcma over a decade ago. our proofs rely on a new technical tool, the traversal lemma, which analyzes the hilbert space a local unitary evolution must traverse under certain conditions. we show that this lemma is essentially tight with respect to the length of the unitary evolution in question.",10.1007/978-3-662-47672-7_50,9/10/2014,1/7/2019,"['gharibian', 'sikora']","['cs', 'physics']"
42,29,1405.6627,portable camera-based product label reading for blind people,"['cs.hc', 'cs.cy']","we propose a camera-based assistive text reading framework to help blind persons read text labels and product packaging from hand-held objects in their daily life. to isolate the object from untidy backgrounds or other surrounding objects in the camera vision, we initially propose an efficient and effective motion based method to define a region of interest (roi) in the video by asking the user to tremble the object. this scheme extracts moving object region by a mixture-of-gaussians-based background subtraction technique. in the extracted roi, text localization and recognition are conducted to acquire text details. to automatically focus the text regions from the object roi, we offer a novel text localization algorithm by learning gradient features of stroke orientations and distributions of edge pixels in an adaboost model. text characters in the localized text regions are then binarized and recognized by off-the-shelf optical character identification software. the renowned text codes are converted into audio output to the blind users. performance of the suggested text localization algorithm is quantitatively evaluated on icdar-2003 and icdar-2011 robust reading datasets. experimental results demonstrate that our algorithm achieves the highest level of developments at present time. the proof-of-concept example is also evaluated on a dataset collected using ten blind persons to evaluate the effectiveness of the scheme. we explore the user interface issues and robustness of the algorithm in extracting and reading text from different objects with complex backgrounds.",10.14445/22315381/ijett-v10p303,5/7/2014,1/16/2019,"['n', 'g', 'n']",['cs']
43,6,1012.0012,domination when the stars are out,"['cs.ds', 'cs.dm']","we algorithmize the recent structural characterization for claw-free graphs by chudnovsky and seymour. building on this result, we show that dominating set on claw-free graphs is (i) fixed-parameter tractable and (ii) even possesses a polynomial kernel. to complement these results, we establish that dominating set is not fixed-parameter tractable on the slightly larger class of graphs that exclude k_{1,4} as an induced subgraph (k_{1,4}-free graphs). we show that our algorithmization can also be used to show that the related connected dominating set problem is fixed-parameter tractable on claw-free graphs. to complement that result, we show that connected dominating set has no polynomial kernel on claw-free graphs and is not fixed-parameter tractable on k_{1,4}-free graphs. combined, our results provide a dichotomy for dominating set and connected dominating set on k_{1,l}-free graphs and show that the problem is fixed-parameter tractable if and only if l <= 3.",,11/30/2010,1/14/2019,"['hermelin', 'mnich', 'van leeuwen', 'woeginger']",['cs']
44,35,1409.8063,on the closest vector problem with a distance guarantee,"['cs.ds', 'cs.cc']","we present a substantially more efficient variant, both in terms of running time and size of preprocessing advice, of the algorithm by liu, lyubashevsky, and micciancio for solving cvpp (the preprocessing version of the closest vector problem, cvp) with a distance guarantee. for instance, for any $\alpha < 1/2$, our algorithm finds the (unique) closest lattice point for any target point whose distance from the lattice is at most $\alpha$ times the length of the shortest nonzero lattice vector, requires as preprocessing advice only $n \approx \widetilde{o}(n \exp(\alpha^2 n /(1-2\alpha)^2))$ vectors, and runs in time $\widetilde{o}(nn)$.   as our second main contribution, we present reductions showing that it suffices to solve cvp, both in its plain and preprocessing versions, when the input target point is within some bounded distance of the lattice. the reductions are based on ideas due to kannan and a recent sparsification technique due to dadush and kun. combining our reductions with the llm algorithm gives an approximation factor of $o(n/\sqrt{\log n})$ for search cvpp, improving on the previous best of $o(n^{1.5})$ due to lagarias, lenstra, and schnorr. when combined with our improved algorithm we obtain, somewhat surprisingly, that only o(n) vectors of preprocessing advice are sufficient to solve cvpp with (the only slightly worse) approximation factor of o(n).",,9/29/2014,12/25/2014,"['dadush', 'regev', 'stephens-davidowitz']",['cs']
45,71,1508.02064,sensitivity study using machine learning algorithms on simulated r-mode   gravitational wave signals from newborn neutron stars,"['astro-ph.im', 'cs.lg']","this is a follow-up sensitivity study on r-mode gravitational wave signals from newborn neutron stars illustrating the applicability of machine learning algorithms for the detection of long-lived gravitational-wave transients. in this sensitivity study we examine three machine learning algorithms (mlas): artificial neural networks (anns), support vector machines (svms) and constrained subspace classifiers (cscs). the objective of this study is to compare the detection efficiency that mlas can achieve with the efficiency of conventional detection algorithms discussed in an earlier paper. comparisons are made using 2 distinct r-mode waveforms. for the training of the mlas we assumed that some information about the distance to the source is given so that the training was performed over distance ranges not wider than half an order of magnitude. the results of this study suggest that machine learning algorithms are suitable for the detection of long-lived gravitational-wave transients and that when assuming knowledge of the distance to the source, mlas are at least as efficient as conventional methods.",10.1103/physrevd.99.024024,8/9/2015,12/6/2018,"['mytidis', 'panagopoulos', 'panagopoulos', 'miller', 'whiting']","['cs', 'physics']"
46,43,1412.7994,solving the shortest vector problem in $2^n$ time via discrete gaussian   sampling,['cs.ds'],"we give a randomized $2^{n+o(n)}$-time and space algorithm for solving the shortest vector problem (svp) on n-dimensional euclidean lattices. this improves on the previous fastest algorithm: the deterministic $\widetilde{o}(4^n)$-time and $\widetilde{o}(2^n)$-space algorithm of micciancio and voulgaris (stoc 2010, siam j. comp. 2013).   in fact, we give a conceptually simple algorithm that solves the (in our opinion, even more interesting) problem of discrete gaussian sampling (dgs). more specifically, we show how to sample $2^{n/2}$ vectors from the discrete gaussian distribution at any parameter in $2^{n+o(n)}$ time and space. (prior work only solved dgs for very large parameters.) our svp result then follows from a natural reduction from svp to dgs. we also show that our dgs algorithm implies a $2^{n + o(n)}$-time algorithm that approximates the closest vector problem to within a factor of $1.97$.   in addition, we give a more refined algorithm for dgs above the so-called smoothing parameter of the lattice, which can generate $2^{n/2}$ discrete gaussian samples in just $2^{n/2+o(n)}$ time and space. among other things, this implies a $2^{n/2+o(n)}$-time and space algorithm for $1.93$-approximate decision svp.",,12/26/2014,9/15/2015,"['aggarwal', 'dadush', 'regev', 'stephens-davidowitz']",['cs']
47,60,1506.00898,extreme compressive sampling for covariance estimation,"['stat.ml', 'cs.it', 'math.it']","this paper studies the problem of estimating the covariance of a collection of vectors using only highly compressed measurements of each vector. an estimator based on back-projections of these compressive samples is proposed and analyzed. a distribution-free analysis shows that by observing just a single linear measurement of each vector, one can consistently estimate the covariance matrix, in both infinity and spectral norm, and this same analysis leads to precise rates of convergence in both norms. via information-theoretic techniques, lower bounds showing that this estimator is minimax-optimal for both infinity and spectral norm estimation problems are established. these results are also specialized to give matching upper and lower bounds for estimating the population covariance of a collection of gaussian vectors, again in the compressive measurement model. the analysis conducted in this paper shows that the effective sample complexity for this problem is scaled by a factor of $m^2/d^2$ where $m$ is the compression dimension and $d$ is the ambient dimension. applications to subspace learning (principal components analysis) and learning over distributed sensor networks are also discussed.",,6/2/2015,1/14/2019,"['azizyan', 'krishnamurthy', 'singh']","['cs', 'stat', 'math']"
48,99,1604.08636,recursive modified pattern search on high-dimensional simplex : a   blackbox optimization technique,"['math.oc', 'cs.ds', 'stat.me']","in this paper, a novel derivative-free pattern search based algorithm for black-box optimization is proposed over a simplex constrained parameter space. at each iteration, starting from the current solution, new possible set of solutions are found by adding a set of derived step-size vectors to the initial starting point. while deriving these step-size vectors, precautions and adjustments are considered so that the set of new possible solution points still remain within the simplex constrained space. thus, no extra time is spent in evaluating the (possibly expensive) objective function at infeasible points (points outside the unit-simplex space). while minimizing any objective function of m parameters, within each iteration, the objective function is evaluated at 2m new possible solution points. so, upto 2m parallel threads can be incorporated which makes the computation even faster while optimizing expensive objective functions over high-dimensional parameter space. once a local minimum is discovered, in order to find a better solution, a novel `re-start' strategy is considered to increase the likelihood of finding a better solution. unlike existing pattern search based methods, a sparsity control parameter is introduced which can be used to induce sparsity in the solution in case the solution is expected to be sparse in prior. a comparative study of the performances of the proposed algorithm and other existing algorithms are shown for a few low, moderate and high-dimensional optimization problems. upto 338 folds improvement in computation time is achieved using the proposed algorithm over genetic algorithm along with better solution. the proposed algorithm is used to estimate the simultaneous quantiles of north atlantic hurricane velocities during 1981-2006 by maximizing a non-closed form likelihood function with (possibly) multiple maximums.",,4/28/2016,1/30/2019,['das'],"['cs', 'stat', 'math']"
49,18,1307.4514,supervised metric learning with generalization guarantees,"['cs.lg', 'cs.ai', 'stat.ml']","the crucial importance of metrics in machine learning algorithms has led to an increasing interest in optimizing distance and similarity functions, an area of research known as metric learning. when data consist of feature vectors, a large body of work has focused on learning a mahalanobis distance. less work has been devoted to metric learning from structured objects (such as strings or trees), most of it focusing on optimizing a notion of edit distance. we identify two important limitations of current metric learning approaches. first, they allow to improve the performance of local algorithms such as k-nearest neighbors, but metric learning for global algorithms (such as linear classifiers) has not been studied so far. second, the question of the generalization ability of metric learning methods has been largely ignored. in this thesis, we propose theoretical and algorithmic contributions that address these limitations. our first contribution is the derivation of a new kernel function built from learned edit probabilities. our second contribution is a novel framework for learning string and tree edit similarities inspired by the recent theory of (e,g,t)-good similarity functions. using uniform stability arguments, we establish theoretical guarantees for the learned similarity that give a bound on the generalization error of a linear classifier built from that similarity. in our third contribution, we extend these ideas to metric learning from feature vectors by proposing a bilinear similarity learning method that efficiently optimizes the (e,g,t)-goodness. generalization guarantees are derived for our approach, highlighting that our method minimizes a tighter bound on the generalization error of the classifier. our last contribution is a framework for establishing generalization bounds for a large class of existing metric learning algorithms based on a notion of algorithmic robustness.",,7/17/2013,7/23/2013,['bellet'],"['cs', 'stat']"
50,9,1202.0515,high-dimensional feature selection by feature-wise kernelized lasso,"['stat.ml', 'cs.ai', 'stat.me']","the goal of supervised feature selection is to find a subset of input features that are responsible for predicting output values. the least absolute shrinkage and selection operator (lasso) allows computationally efficient feature selection based on linear dependency between input features and output values. in this paper, we consider a feature-wise kernelized lasso for capturing non-linear input-output dependency. we first show that, with particular choices of kernel functions, non-redundant features with strong statistical dependence on output values can be found in terms of kernel-based independence measures. we then show that the globally optimal solution can be efficiently computed; this makes the approach scalable to high-dimensional problems. the effectiveness of the proposed method is demonstrated through feature selection experiments with thousands of features.",10.1162/neco_a_00537,2/2/2012,1/3/2019,"['yamada', 'jitkrittum', 'sigal', 'xing', 'sugiyama']","['cs', 'stat']"
51,63,1506.0303900000001,measuring sample quality with stein's method,"['stat.ml', 'cs.lg', 'math.pr', 'stat.me']","to improve the efficiency of monte carlo estimation, practitioners are turning to biased markov chain monte carlo procedures that trade off asymptotic exactness for computational speed. the reasoning is sound: a reduction in variance due to more rapid sampling can outweigh the bias introduced. however, the inexactness creates new challenges for sampler and parameter selection, since standard measures of sample quality like effective sample size do not account for asymptotic bias. to address these challenges, we introduce a new computable quality measure based on stein's method that quantifies the maximum discrepancy between sample and target expectations over a large class of test functions. we use our tool to compare exact, biased, and deterministic sample sequences and illustrate applications to hyperparameter selection, convergence rate assessment, and quantifying bias-variance tradeoffs in posterior inference.",,6/9/2015,12/31/2018,"['gorham', 'mackey']","['cs', 'stat', 'math']"
52,93,1603.0316,near-optimality of linear strategies for static teams with `big'   non-gaussian noise,"['math.oc', 'cs.gt', 'cs.it', 'math.it']","we study stochastic team problems with static information structure where we assume controllers have linear information and quadratic cost but allow the noise to be from a non-gaussian class. when the noise is gaussian, it is well known that these problems admit linear optimal controllers. we show that for such linear-quadratic static teams with any log-concave noise, if the length of the noise or data vector becomes large compared to the size of the team and their observations, then linear strategies approach optimality for `most' problems. the quality of the approximation improves as length of the noise vector grows and the class of problems for which the approximation is asymptotically not exact approaches a set of measure zero. we show that if the optimal strategies for problems with log-concave noise converge pointwise, they do so to the (linear) optimal strategy for the problem with gaussian noise. and we derive an asymptotically tight error bound on the difference between the optimal cost for the non-gaussian problem and the best cost obtained under linear strategies.",,3/10/2016,12/28/2018,['kulkarni'],"['cs', 'math']"
53,33,1409.0177,persistent homology in sparse regression and its application to brain   morphometry,"['stat.me', 'cs.cv']","sparse systems are usually parameterized by a tuning parameter that determines the sparsity of the system. how to choose the right tuning parameter is a fundamental and difficult problem in learning the sparse system. in this paper, by treating the the tuning parameter as an additional dimension, persistent homological structures over the parameter space is introduced and explored. the structures are then further exploited in speeding up the computation using the proposed soft-thresholding technique. the topological structures are further used as multivariate features in the tensor-based morphometry (tbm) in characterizing white matter alterations in children who have experienced severe early life stress and maltreatment. these analyses reveal that stress-exposed children exhibit more diffuse anatomical organization across the whole white matter region.",10.1109/tmi.2015.2416271,8/30/2014,3/9/2015,"['chung', 'hanson', 'ye', 'davidson', 'pollak']","['cs', 'stat']"
54,37,1411.1635,scientometrics and information retrieval - weak-links revitalized,"['cs.ir', 'cs.dl']","this special issue brings together eight papers from experts of communities which often have been perceived as different once: bibliometrics, scientometrics and informetrics on the one side and information retrieval on the other. the idea of this special issue started at the workshop ""combining bibliometrics and information retrieval"" held at the 14th international conference of scientometrics and informetrics, vienna, july 14-19, 2013. our motivation as guest editors started from the observation that main discourses in both fields are different, that communities are only partly overlapping and from the belief that a knowledge transfer would be profitable for both sides.",10.1007/s11192-014-1484-3,11/6/2014,,"['mayr', 'scharnhorst']",['cs']
55,97,1604.0517,a repeated signal difference for recognising patterns,"['cs.ne', 'cs.ai', 'q-bio.nc']","this paper describes a new mechanism that might help with defining pattern sequences, by the fact that it can produce an upper bound on the ensemble value that can persistently oscillate with the actual values produced from each pattern. with every firing event, a node also receives an on/off feedback switch. if the node fires, then it sends a feedback result depending on the input signal strength. if the input signal is positive or larger, it can store an 'on' switch feedback for the next iteration. if the signal is negative or smaller, it can store an 'off' switch feedback for the next iteration. if the node does not fire, then it does not affect the current feedback situation and receives the switch command produced by the last active pattern event for the same neuron. the upper bound therefore also represents the largest or most enclosing pattern set and the lower value is for the actual set of firing patterns. if the pattern sequence repeats, it will oscillate between the two values, allowing them to be recognised and measured more easily, over time. tests show that changing the sequence ordering produces different value sets, which can also be measured.",,4/18/2016,9/7/2016,['greer'],"['cs', 'q-bio']"
56,32,1408.1147,classification of the z2z4-linear hadamard codes and their automorphism   groups,"['cs.it', 'math.co', 'math.it']","a $z_2z_4$-linear hadamard code of length $\alpha+2\beta=2^t$ is a binary hadamard code which is the gray map image of a $z_2z_4$-additive code with $\alpha$ binary coordinates and $\beta$ quaternary coordinates. it is known that there are exactly $[(t-1)/2]$ and $[t/2]$ nonequivalent $z_2z_4$-linear hadamard codes of length $2^t$, with $\alpha=0$ and $\alpha\not=0$, respectively, for all $t\geq 3$. in this paper, it is shown that each $z_2z_4$-linear hadamard code with $\alpha=0$ is equivalent to a $z_2z_4$-linear hadamard code with $\alpha\not=0$; so there are only $[t/2]$ nonequivalent $z_2z_4$-linear hadamard codes of length $2^t$. moreover, the order of the monomial automorphism group for the $z_2z_4$-additive hadamard codes and the permutation automorphism group of the corresponding $z_2z_4$-linear hadamard codes are given.",10.1109/tit.2014.2379644,8/5/2014,1/9/2019,"['krotov', 'villanueva']","['cs', 'math']"
57,58,1505.0585199999998,on the likelihood of single-peaked preferences,"['cs.gt', 'math.co']","this paper contains an extensive combinatorial analysis of the single-peaked domain restriction and investigates the likelihood that an election is single-peaked. we provide a very general upper bound result for domain restrictions that can be defined by certain forbidden configurations. this upper bound implies that many domain restrictions (including the single-peaked restriction) are very unlikely to appear in a random election chosen according to the impartial culture assumption. for single-peaked elections, this upper bound can be refined and complemented by a lower bound that is asymptotically tight. in addition, we provide exact results for elections with few voters or candidates. moreover, we consider the p\'{o}lya urn model and the mallows model and obtain lower bounds showing that single-peakedness is considerably more likely to appear for certain parameterizations.",10.1007/s00355-017-1033-0,5/20/2015,1/28/2019,"['lackner', 'lackner']","['cs', 'math']"
58,7,1105.4042,adaptive and optimal online linear regression on $\ell^1$-balls,"['stat.ml', 'cs.lg', 'math.st', 'stat.th']","we consider the problem of online linear regression on individual sequences. the goal in this paper is for the forecaster to output sequential predictions which are, after $t$ time rounds, almost as good as the ones output by the best linear predictor in a given $\ell^1$-ball in $\\r^d$. we consider both the cases where the dimension~$d$ is small and large relative to the time horizon $t$. we first present regret bounds with optimal dependencies on $d$, $t$, and on the sizes $u$, $x$ and $y$ of the $\ell^1$-ball, the input data and the observations. the minimax regret is shown to exhibit a regime transition around the point $d = \sqrt{t} u x / (2 y)$. furthermore, we present efficient algorithms that are adaptive, \ie, that do not require the knowledge of $u$, $x$, $y$, and $t$, but still achieve nearly optimal regret bounds.",,5/20/2011,1/16/2019,"['gerchinovitz', 'yu']","['cs', 'stat', 'math']"
59,82,1511.06866,feedback capacity of gaussian channels revisited,"['cs.it', 'math.it', 'math.oc']","in this paper, we revisit the problem of finding the average capacity of the gaussian feedback channel. first, we consider the problem of finding the average capacity of the analog gaussian noise channel where the noise has an arbitrary spectral density. we introduce a new approach to the problem where we solve the problem over a finite number of transmissions and then consider the limit of an infinite number of transmissions. further, we consider the important special case of stationary gaussian noise with finite memory. we show that the channel capacity at stationarity can be found by solving a semi-definite program, and hence computationally tractable. we also give new proofs and results of the non stationary solution which bridges the gap between results in the literature for the stationary and non stationary feedback channel capacities. it's shown that a linear communication feedback strategy is optimal. similar to the solution of the stationary problem, it's shown that the optimal linear strategy is to transmit a linear combination of the information symbols to be communicated and the innovations for the estimation error of the state of the noise process.",,11/21/2015,1/23/2019,['gattami'],"['cs', 'math']"
60,39,1411.2647,asynchronous approximation of a single component of the solution to a   linear system,['cs.ds'],"we present a distributed asynchronous algorithm for approximating a single component of the solution to a system of linear equations $ax = b$, where $a$ is a positive definite real matrix, and $b \in \mathbb{r}^n$. this is equivalent to solving for $x_i$ in $x = gx + z$ for some $g$ and $z$ such that the spectral radius of $g$ is less than 1. our algorithm relies on the neumann series characterization of the component $x_i$, and is based on residual updates. we analyze our algorithm within the context of a cloud computation model, in which the computation is split into small update tasks performed by small processors with shared access to a distributed file system. we prove a robust asymptotic convergence result when the spectral radius $\rho(|g|) < 1$, regardless of the precise order and frequency in which the update tasks are performed. we provide convergence rate bounds which depend on the order of update tasks performed, analyzing both deterministic update rules via counting weighted random walks, as well as probabilistic update rules via concentration bounds. the probabilistic analysis requires analyzing the product of random matrices which are drawn from distributions that are time and path dependent. we specifically consider the setting where $n$ is large, yet $g$ is sparse, e.g., each row has at most $d$ nonzero entries. this is motivated by applications in which $g$ is derived from the edge structure of an underlying graph. our results prove that if the local neighborhood of the graph does not grow too quickly as a function of $n$, our algorithm can provide significant reduction in computation cost as opposed to any algorithm which computes the global solution vector $x$. our algorithm obtains an $\epsilon \|x\|_2$ additive approximation for $x_i$ in constant time with respect to the size of the matrix when the maximum row sparsity $d = o(1)$ and $1/(1-\|g\|_2) = o(1)$.",,11/10/2014,1/21/2019,"['ozdaglar', 'shah', 'yu']",['cs']
61,69,1507.08235,algorithmic aspects of rotor-routing and the notion of linear   equivalence,"['math.co', 'cs.cc']","we define the analogue of linear equivalence of graph divisors for the rotor-router model, and use it to prove polynomial time computability of some problems related to rotor-routing. using the connection between linear equivalence for chip-firing and for rotor-routing, we give a simple proof for the fact that the number of rotor-router unicycle-orbits equals the order of the picard group. we also show that the rotor-router action of the picard group on the set of spanning in-arborescences can be interpreted in terms of the linear equivalence.",,7/29/2015,1/14/2019,['tóthmérész'],"['cs', 'math']"
62,10,1203.0905,autocalibration with the minimum number of cameras with known pixel   shape,['cs.cv'],"in 3d reconstruction, the recovery of the calibration parameters of the cameras is paramount since it provides metric information about the observed scene, e.g., measures of angles and ratios of distances. autocalibration enables the estimation of the camera parameters without using a calibration device, but by enforcing simple constraints on the camera parameters. in the absence of information about the internal camera parameters such as the focal length and the principal point, the knowledge of the camera pixel shape is usually the only available constraint. given a projective reconstruction of a rigid scene, we address the problem of the autocalibration of a minimal set of cameras with known pixel shape and otherwise arbitrarily varying intrinsic and extrinsic parameters. we propose an algorithm that only requires 5 cameras (the theoretical minimum), thus halving the number of cameras required by previous algorithms based on the same constraint. to this purpose, we introduce as our basic geometric tool the six-line conic variety (slcv), consisting in the set of planes intersecting six given lines of 3d space in points of a conic. we show that the set of solutions of the euclidean upgrading problem for three cameras with known pixel shape can be parameterized in a computationally efficient way. this parameterization is then used to solve autocalibration from five or more cameras, reducing the three-dimensional search space to a two-dimensional one. we provide experiments with real images showing the good performance of the technique.",10.1007/s10851-014-0492-5,3/5/2012,1/10/2014,"['ronda', 'valdés', 'gallego']",['cs']
63,80,1511.04338,the sensorimotor loop as a dynamical system: how regular motion   primitives may emerge from self-organized limit cycles,"['q-bio.nc', 'cond-mat.dis-nn', 'cs.ro']","we investigate the sensorimotor loop of simple robots simulated within the lpzrobots environment from the point of view of dynamical systems theory. for a robot with a cylindrical shaped body and an actuator controlled by a single proprioceptual neuron we find various types of periodic motions in terms of stable limit cycles. these are self-organized in the sense, that the dynamics of the actuator kicks in only, for a certain range of parameters, when the barrel is already rolling, stopping otherwise. the stability of the resulting rolling motions terminates generally, as a function of the control parameters, at points where fold bifurcations of limit cycles occur. we find that several branches of motion types exist for the same parameters, in terms of the relative frequencies of the barrel and of the actuator, having each their respective basins of attractions in terms of initial conditions. for low drivings stable limit cycles describing periodic and drifting back-and-forth motions are found additionally. these modes allow to generate symmetry breaking explorative behavior purely by the timing of an otherwise neutral signal with respect to the cyclic back-and-forth motion of the robot.",10.3389/frobt.2015.00031,11/13/2015,3/14/2018,"['sándor', 'jahn', 'martin', 'gros']","['cs', 'q-bio', 'physics']"
64,16,1306.6709,a survey on metric learning for feature vectors and structured data,"['cs.lg', 'cs.ai', 'stat.ml']","the need for appropriate ways to measure the distance or similarity between data is ubiquitous in machine learning, pattern recognition and data mining, but handcrafting such good metrics for specific problems is generally difficult. this has led to the emergence of metric learning, which aims at automatically learning a metric from data and has attracted a lot of interest in machine learning and related fields for the past ten years. this survey paper proposes a systematic review of the metric learning literature, highlighting the pros and cons of each approach. we pay particular attention to mahalanobis distance metric learning, a well-studied and successful framework, but additionally present a wide range of methods that have recently emerged as powerful alternatives, including nonlinear metric learning, similarity learning and local metric learning. recent trends and extensions, such as semi-supervised metric learning, metric learning for histogram data and the derivation of generalization guarantees, are also covered. finally, this survey addresses metric learning for structured data, in particular edit distance learning, and attempts to give an overview of the remaining challenges in metric learning for the years to come.",,6/27/2013,2/12/2014,"['bellet', 'habrard', 'sebban']","['cs', 'stat']"
65,26,1404.2644,a distributed frank-wolfe algorithm for communication-efficient sparse   learning,"['cs.dc', 'cs.ai', 'cs.lg', 'stat.ml']","learning sparse combinations is a frequent theme in machine learning. in this paper, we study its associated optimization problem in the distributed setting where the elements to be combined are not centrally located but spread over a network. we address the key challenges of balancing communication costs and optimization errors. to this end, we propose a distributed frank-wolfe (dfw) algorithm. we obtain theoretical guarantees on the optimization error $\epsilon$ and communication cost that do not depend on the total number of combining elements. we further show that the communication cost of dfw is optimal by deriving a lower-bound on the communication cost required to construct an $\epsilon$-approximate solution. we validate our theoretical analysis with empirical studies on synthetic and real-world data, which demonstrate that dfw outperforms both baselines and competing methods. we also study the performance of dfw when the conditions of our analysis are relaxed, and show that dfw is fairly robust.",,4/9/2014,1/12/2015,"['bellet', 'liang', 'garakani', 'balcan', 'sha']","['cs', 'stat']"
66,44,1412.8356,bloom filters in adversarial environments,['cs.cr'],"many efficient data structures use randomness, allowing them to improve upon deterministic ones. usually, their efficiency and correctness are analyzed using probabilistic tools under the assumption that the inputs and queries are independent of the internal randomness of the data structure. in this work, we consider data structures in a more robust model, which we call the adversarial model. roughly speaking, this model allows an adversary to choose inputs and queries adaptively according to previous responses. specifically, we consider a data structure known as ""bloom filter"" and prove a tight connection between bloom filters in this model and cryptography.   a bloom filter represents a set $s$ of elements approximately, by using fewer bits than a precise representation. the price for succinctness is allowing some errors: for any $x \in s$ it should always answer `yes', and for any $x \notin s$ it should answer `yes' only with small probability.   in the adversarial model, we consider both efficient adversaries (that run in polynomial time) and computationally unbounded adversaries that are only bounded in the number of queries they can make. for computationally bounded adversaries, we show that non-trivial (memory-wise) bloom filters exist if and only if one-way functions exist. for unbounded adversaries we show that there exists a bloom filter for sets of size $n$ and error $\varepsilon$, that is secure against $t$ queries and uses only $o(n \log{\frac{1}{\varepsilon}}+t)$ bits of memory. in comparison, $n\log{\frac{1}{\varepsilon}}$ is the best possible under a non-adaptive adversary.",,12/29/2014,1/29/2019,"['naor', 'yogev']",['cs']
67,81,1511.05464,extending gossip algorithms to distributed estimation of u-statistics,"['stat.ml', 'cs.dc', 'cs.lg', 'cs.sy', 'stat.co']","efficient and robust algorithms for decentralized estimation in networks are essential to many distributed systems. whereas distributed estimation of sample mean statistics has been the subject of a good deal of attention, computation of $u$-statistics, relying on more expensive averaging over pairs of observations, is a less investigated area. yet, such data functionals are essential to describe global properties of a statistical population, with important examples including area under the curve, empirical variance, gini mean difference and within-cluster point scatter. this paper proposes new synchronous and asynchronous randomized gossip algorithms which simultaneously propagate data across the network and maintain local estimates of the $u$-statistic of interest. we establish convergence rate bounds of $o(1/t)$ and $o(\log t / t)$ for the synchronous and asynchronous cases respectively, where $t$ is the number of iterations, with explicit data and network dependent terms. beyond favorable comparisons in terms of rate analysis, numerical experiments provide empirical evidence the proposed algorithms surpasses the previously introduced approach.",,11/17/2015,,"['colin', 'bellet', 'salmon', 'clémençon']","['cs', 'stat']"
68,73,1510.06175,"wireless communication, identification and sensing technologies enabling   integrated logistics: a study in the harbor environment",['cs.oh'],"in the last decade, integrated logistics has become an important challenge in the development of wireless communication, identification and sensing technology, due to the growing complexity of logistics processes and the increasing demand for adapting systems to new requirements. the advancement of wireless technology provides a wide range of options for the maritime container terminals. electronic devices employed in container terminals reduce the manual effort, facilitating timely information flow and enhancing control and quality of service and decision made. in this paper, we examine the technology that can be used to support integration in harbor's logistics. in the literature, most systems have been developed to address specific needs of particular harbors, but a systematic study is missing. the purpose is to provide an overview to the reader about which technology of integrated logistics can be implemented and what remains to be addressed in the future.",,10/21/2015,,"['cimino', 'celandroni', 'ferro', 'la rosa', 'palumbo', 'vaglini']",['cs']
69,22,1311.1714,kahip v2.1 -- karlsruhe high quality partitioning -- user guide,"['cs.dc', 'cs.ds']","this paper serves as a user guide to the graph partitioning framework kahip (karlsruhe high quality partitioning). we give a rough overview of the techniques used within the framework and describe the user interface as well as the file formats used. moreover, we provide a short description of the current library functions provided within the framework.",,11/7/2013,1/4/2019,"['sanders', 'schulz']",['cs']
70,70,1507.08258,perfect secrecy under deep random assumption,['cs.cr'],"we present a new idea to design perfectly secure information exchange protocol, based on so called deep randomness, which means randomness relying on hidden probability distribution. such idea drives us to introduce a new axiom in probability theory, thanks to which we can design a protocol, beyond shannon limit, enabling two legitimate partners, sharing originally no common private information, to exchange secret information with accuracy as close as desired from perfection, and knowledge as close as desired from zero by any unlimitedly powered opponent.",,7/29/2015,1/6/2019,['de valroger'],['cs']
71,23,1312.0496,verifying whether one-tape non-deterministic turing machines run in time   $cn+d$,"['cs.cc', 'cs.fl']","we discuss the following family of problems, parameterized by integers $c\geq 2$ and $d\geq 1$: does a given one-tape non-deterministic $q$-state turing machine make at most $cn+d$ steps on all computations on all inputs of length $n$, for all $n$?   assuming a fixed tape and input alphabet, we show that these problems are co-np-complete and we provide good non-deterministic and co-non-deterministic lower bounds. specifically, these problems can not be solved in $o(q^{(c-1)/4})$ non-deterministic time by multi-tape turing machines. we also show that the complements of these problems can be solved in $o(q^{c+2})$ non-deterministic time and not in $o(q^{(c-1)/2})$ non-deterministic time by multi-tape turing machines.",,12/2/2013,5/19/2014,['gajser'],['cs']
72,4,1004.3385,modularity and optimality in social choice,"['math.co', 'cs.dm', 'math.at', 'physics.soc-ph']","marengo and the second author have developed in the last years a geometric model of social choice when this takes place among bundles of interdependent elements, showing that by bundling and unbundling the same set of constituent elements an authority has the power of determining the social outcome. in this paper we will tie the model above to tournament theory, solving some of the mathematical problems arising in their work and opening new questions which are interesting not only from a mathematical and a social choice point of view, but also from an economic and a genetic one. in particular, we will introduce the notion of u-local optima and we will study it from both a theoretical and a numerical/probabilistic point of view; we will also describe an algorithm that computes the universal basin of attraction of a social outcome in o(m^3 logm) time (where m is the number of social outcomes).",10.1080/0022250x.2011.556769,4/20/2010,,"['amendola', 'settepanella']","['cs', 'physics', 'math']"
73,42,1412.0179999999998,empirical q-value iteration,"['math.oc', 'cs.lg']","we propose a new simple and natural algorithm for learning the optimal q-value function of a discounted-cost markov decision process (mdp) when the transition kernels are unknown. unlike the classical learning algorithms for mdps, such as q-learning and actor-critic algorithms, this algorithm doesn't depend on a stochastic approximation-based method. we show that our algorithm, which we call the empirical q-value iteration (eqvi) algorithm, converges to the optimal q-value function. we also give a rate of convergence or a non-asymptotic sample complexity bound, and also show that an asynchronous (or online) version of the algorithm will also work. preliminary experimental results suggest a faster rate of convergence to a ball park estimate for our algorithm compared to stochastic approximation-based algorithms.",,11/30/2014,1/29/2019,"['kalathil', 'borkar', 'jain']","['cs', 'math']"
74,66,1507.0484,proof of the wilf-zeilberger conjecture for mixed hypergeometric terms,"['math.co', 'cs.sc']","in 1992, wilf and zeilberger conjectured that a hypergeometric term in several discrete and continuous variables is holonomic if and only if it is proper. strictly speaking the conjecture does not hold, but it is true when reformulated properly: payne proved a piecewise interpretation in 1997, and independently, abramov and petkovsek in 2002 proved a conjugate interpretation. both results address the pure discrete case of the conjecture. in this paper we extend their work to hypergeometric terms in several discrete and continuous variables and prove the conjugate interpretation of the wilf-zeilberger conjecture in this mixed setting.",10.1016/j.jsc.2018.06.003,7/17/2015,6/8/2018,"['chen', 'koutschan']","['cs', 'math']"
75,19,1308.4371,a new key establishment protocol and its application in pay-tv systems,['cs.cr'],"a pay-tv consumer uses a decoder to access encrypted digital content. to this end, the decoder contains a chip capable of decrypting the content if provisioned with the appropriate content decryption keys. a key establishment protocol is used to secure the delivery of the content decryption keys to the chip. this paper presents a new protocol and shows how the protocol can be applied in a pay-tv system. compared to existing protocols, the presented solution reduces the risk that decoders need to be replaced in order to correct a security breach. the new protocol has recently been incorporated in an etsi standard.",10.1109/icce-berlin.2018.8576245,8/20/2013,12/31/2018,['roelse'],['cs']
76,92,1603.02981,ant-inspired density estimation via random walks,"['cs.dc', 'cs.ds']","many ant species employ distributed population density estimation in applications ranging from quorum sensing [pra05], to task allocation [gor99], to appraisal of enemy colony strength [ada90]. it has been shown that ants estimate density by tracking encounter rates -- the higher the population density, the more often the ants bump into each other [pra05,gpt93].   we study distributed density estimation from a theoretical perspective. we prove that a group of anonymous agents randomly walking on a grid are able to estimate their density within a small multiplicative error in few steps by measuring their rates of encounter with other agents. despite dependencies inherent in the fact that nearby agents may collide repeatedly (and, worse, cannot recognize when this happens), our bound nearly matches what would be required to estimate density by independently sampling grid locations.   from a biological perspective, our work helps shed light on how ants and other social insects can obtain relatively accurate density estimates via encounter rates. from a technical perspective, our analysis provides new tools for understanding complex dependencies in the collision probabilities of multiple random walks. we bound the strength of these dependencies using $local\ mixing\ properties$ of the underlying graph. our results extend beyond the grid to more general graphs and we discuss applications to size estimation for social networks and density estimation for robot swarms.",,3/9/2016,1/2/2019,"['musco', 'su', 'lynch']",['cs']
77,25,1403.6563,fully abstract game semantics for actors,['cs.lo'],"based on the work on the algebraic theory of actors and game semantics for asynchronous $\pi$ calculus, we give the full abstraction proof of game semantics for actors.",,3/25/2014,1/6/2019,['wang'],['cs']
78,79,1511.0373,operator scaling: theory and applications,"['cs.cc', 'math.ac', 'math.ag', 'quant-ph']","in this paper we present a deterministic polynomial time algorithm for testing if a symbolic matrix in non-commuting variables over $\mathbb{q}$ is invertible or not. the analogous question for commuting variables is the celebrated polynomial identity testing (pit) for symbolic determinants. in contrast to the commutative case, which has an efficient probabilistic algorithm, the best previous algorithm for the non-commutative setting required exponential time (whether or not randomization is allowed). the algorithm efficiently solves the ""word problem"" for the free skew field, and the identity testing problem for arithmetic formulae with division over non-commuting variables, two problems which had only exponential-time algorithms prior to this work.   the main contribution of this paper is a complexity analysis of an existing algorithm due to gurvits, who proved it was polynomial time for certain classes of inputs. we prove it always runs in polynomial time. the main component of our analysis is a simple (given the necessary known tools) lower bound on central notion of capacity of operators (introduced by gurvits). we extend the algorithm to actually approximate capacity to any accuracy in polynomial time, and use this analysis to give quantitative bounds on the continuity of capacity (the latter is used in a subsequent paper on brascamp-lieb inequalities).   symbolic matrices in non-commuting variables, and the related structural and algorithmic questions, have a remarkable number of diverse origins and motivations. they arise independently in (commutative) invariant theory and representation theory, linear algebra, optimization, linear system theory, quantum information theory, approximation of the permanent and naturally in non-commutative algebra. we provide a detailed account of some of these sources and their interconnections.",,11/11/2015,1/23/2019,"['garg', 'gurvits', 'oliveira', 'wigderson']","['cs', 'physics', 'math']"
79,48,1502.00326,adaptive estimation of shannon entropy,"['cs.it', 'math.it']","we consider estimating the shannon entropy of a discrete distribution $p$ from $n$ i.i.d. samples. recently, jiao, venkat, han, and weissman, and wu and yang constructed approximation theoretic estimators that achieve the minimax $l_2$ rates in estimating entropy. their estimators are consistent given $n \gg \frac{s}{\ln s}$ samples, where $s$ is the alphabet size, and it is the best possible sample complexity. in contrast, the maximum likelihood estimator (mle), which is the empirical entropy, requires $n\gg s$ samples.   in the present paper we significantly refine the minimax results of existing work. to alleviate the pessimism of minimaxity, we adopt the adaptive estimation framework, and show that the minimax rate-optimal estimator in jiao, venkat, han, and weissman achieves the minimax rates simultaneously over a nested sequence of subsets of distributions $p$, without knowing the alphabet size $s$ or which subset $p$ lies in. in other words, their estimator is adaptive with respect to this nested sequence of the parameter space, which is characterized by the entropy of the distribution. we also characterize the maximum risk of the mle over this nested sequence, and show, for every subset in the sequence, that the performance of the minimax rate-optimal estimator with $n$ samples is essentially that of the mle with $n\ln n$ samples, thereby further substantiating the generality of the phenomenon identified by jiao, venkat, han, and weissman.",,2/1/2015,1/1/2019,"['han', 'jiao', 'weissman']","['cs', 'math']"
80,49,1502.05746,binary embedding: fundamental limits and fast algorithm,"['cs.ds', 'cs.it', 'math.it']","binary embedding is a nonlinear dimension reduction methodology where high dimensional data are embedded into the hamming cube while preserving the structure of the original space. specifically, for an arbitrary $n$ distinct points in $\mathbb{s}^{p-1}$, our goal is to encode each point using $m$-dimensional binary strings such that we can reconstruct their geodesic distance up to $\delta$ uniform distortion. existing binary embedding algorithms either lack theoretical guarantees or suffer from running time $o\big(mp\big)$. we make three contributions: (1) we establish a lower bound that shows any binary embedding oblivious to the set of points requires $m = \omega(\frac{1}{\delta^2}\log{n})$ bits and a similar lower bound for non-oblivious embeddings into hamming distance; (2) [deleted, see comment]; (3) we also provide an analytic result about embedding a general set of points $k \subseteq \mathbb{s}^{p-1}$ with even infinite size. our theoretical findings are supported through experiments on both synthetic and real data sets.",,2/19/2015,1/22/2019,"['yi', 'caramanis', 'price']","['cs', 'math']"
81,61,1506.01188,online influence maximization (extended version),"['cs.si', 'cs.db', 'physics.soc-ph']","social networks are commonly used for marketing purposes. for example, free samples of a product can be given to a few influential social network users (or ""seed nodes""), with the hope that they will convince their friends to buy it. one way to formalize marketers' objective is through influence maximization (or im), whose goal is to find the best seed nodes to activate under a fixed budget, so that the number of people who get influenced in the end is maximized. recent solutions to im rely on the influence probability that a user influences another one. however, this probability information may be unavailable or incomplete. in this paper, we study im in the absence of complete information on influence probability. we call this problem online influence maximization (oim) since we learn influence probabilities at the same time we run influence campaigns. to solve oim, we propose a multiple-trial approach, where (1) some seed nodes are selected based on existing influence information; (2) an influence campaign is started with these seed nodes; and (3) users' feedback is used to update influence information. we adopt the explore-exploit strategy, which can select seed nodes using either the current influence probability estimation (exploit), or the confidence bound on the estimation (explore). any existing im algorithm can be used in this framework. we also develop an incremental algorithm that can significantly reduce the overhead of handling users' feedback information. our experiments show that our solution is more effective than traditional im methods on the partial information.",10.1145/2783258.2783271,6/3/2015,,"['lei', 'maniu', 'mo', 'cheng', 'senellart']","['cs', 'physics']"
82,36,1411.1367,choosing by means of approval-preferential voting. the path-revised   approval choice,['cs.gt'],"approval-preferential voting is problematical since it combines two different kinds of information that could by themselves lead to different choices. this article analyses the problem and studies a new proposal to deal with it. the existing methods are overviewed with special attention to several desirable properties that are not always met. particular emphasis is made on certain rather unknown views of condorcet about this subject. the proposed procedure definitely aims for a choice in the spirit of approval voting. however, it still makes use of the preferential information so as to improve the approval one. this is done by means of the path scores, in common to schulze's method for preferential voting. the resulting method, that we call path-revised approval choice, is shown to enjoy several good properties. in particular, it fulfils in a well-defined sense condorcet's latest view that a surely good option should prevail over a doubtfully best one.",,11/3/2014,1/22/2019,"['camps', 'mora', 'saumell']",['cs']
83,53,1504.01995,solving the closest vector problem in $2^n$ time--- the discrete   gaussian strikes again!,['cs.ds'],"we give a $2^{n+o(n)}$-time and space randomized algorithm for solving the exact closest vector problem (cvp) on $n$-dimensional euclidean lattices. this improves on the previous fastest algorithm, the deterministic $\widetilde{o}(4^{n})$-time and $\widetilde{o}(2^{n})$-space algorithm of micciancio and voulgaris.   we achieve our main result in three steps. first, we show how to modify the sampling algorithm from [adrs15] to solve the problem of discrete gaussian sampling over lattice shifts, $l- t$, with very low parameters. while the actual algorithm is a natural generalization of [adrs15], the analysis uses substantial new ideas. this yields a $2^{n+o(n)}$-time algorithm for approximate cvp for any approximation factor $\gamma = 1+2^{-o(n/\log n)}$. second, we show that the approximate closest vectors to a target vector $t$ can be grouped into ""lower-dimensional clusters,"" and we use this to obtain a recursive reduction from exact cvp to a variant of approximate cvp that ""behaves well with these clusters."" third, we show that our discrete gaussian sampling algorithm can be used to solve this variant of approximate cvp.   the analysis depends crucially on some new properties of the discrete gaussian distribution and approximate closest vectors, which might be of independent interest.",,4/8/2015,9/28/2015,"['aggarwal', 'dadush', 'stephens-davidowitz']",['cs']
84,94,1603.05095,improved bounds on the epidemic threshold of exact sis models on complex   networks,"['cs.si', 'math.ds', 'physics.soc-ph']","the sis (susceptible-infected-susceptible) epidemic model on an arbitrary network, without making approximations, is a $2^n$-state markov chain with a unique absorbing state (the all-healthy state). this makes analysis of the sis model and, in particular, determining the threshold of epidemic spread quite challenging. it has been shown that the exact marginal probabilities of infection can be upper bounded by an $n$-dimensional linear time-invariant system, a consequence of which is that the markov chain is ""fast-mixing"" when the lti system is stable, i.e. when $\frac{\beta}{\delta}<\frac{1}{\lambda_{\max}(a)}$ (where $\beta$ is the infection rate per link, $\delta$ is the recovery rate, and $\lambda_{\max}(a)$ is the largest eigenvalue of the network's adjacency matrix). this well-known threshold has been recently shown not to be tight in several cases, such as in a star network. in this paper, we provide tighter upper bounds on the exact marginal probabilities of infection, by also taking pairwise infection probabilities into account. based on this improved bound, we derive tighter eigenvalue conditions that guarantee fast mixing (i.e., logarithmic mixing time) of the chain. we demonstrate the improvement of the threshold condition by comparing the new bound with the known one on various networks and epidemic parameters.",10.1109/cdc.2016.7798804,3/16/2016,,"['ruhi', 'thrampoulidis', 'hassibi']","['cs', 'physics', 'math']"
85,77,1511.0229,combining privileged information to improve context-aware recommender   systems,"['cs.ir', 'cs.ai']","a recommender system is an information filtering technology which can be used to predict preference ratings of items (products, services, movies, etc) and/or to output a ranking of items that are likely to be of interest to the user. context-aware recommender systems (cars) learn and predict the tastes and preferences of users by incorporating available contextual information in the recommendation process. one of the major challenges in context-aware recommender systems research is the lack of automatic methods to obtain contextual information for these systems. considering this scenario, in this paper, we propose to use contextual information from topic hierarchies of the items (web pages) to improve the performance of context-aware recommender systems. the topic hierarchies are constructed by an extension of the lupi-based incremental hierarchical clustering method that considers three types of information: traditional bag-of-words (technical information), and the combination of named entities (privileged information i) with domain terms (privileged information ii). we evaluated the contextual information in four context-aware recommender systems. different weights were assigned to each type of information. the empirical results demonstrated that topic hierarchies with the combination of the two kinds of privileged information can provide better recommendations.",,11/6/2015,1/4/2019,"['sundermann', 'domingues', 'marcacini', 'rezende']",['cs']
86,0,707.3575,an exploratory study of google scholar,"['cs.dl', 'cs.ir']","the paper discusses and analyzes the scientific search service google scholar (gs). the focus is on an exploratory study which investigates the coverage of scientific serials in gs. the study shows deficiencies in the coverage and up-to-dateness of the gs index. furthermore, the study points up which web servers are the most important data providers for this search service and which information sources are highly represented. we can show that there is a relatively large gap in google scholars coverage of german literature as well as weaknesses in the accessibility of open access content.   keywords: search engines, digital libraries, worldwide web, serials, electronic journals",10.1108/14684520710841784,7/24/2007,,"['mayr', 'walter']",['cs']
87,86,1601.04586,sparse convex clustering,"['stat.me', 'cs.lg', 'stat.ml']","convex clustering, a convex relaxation of k-means clustering and hierarchical clustering, has drawn recent attentions since it nicely addresses the instability issue of traditional nonconvex clustering methods. although its computational and statistical properties have been recently studied, the performance of convex clustering has not yet been investigated in the high-dimensional clustering scenario, where the data contains a large number of features and many of them carry no information about the clustering structure. in this paper, we demonstrate that the performance of convex clustering could be distorted when the uninformative features are included in the clustering. to overcome it, we introduce a new clustering method, referred to as sparse convex clustering, to simultaneously cluster observations and conduct feature selection. the key idea is to formulate convex clustering in a form of regularization, with an adaptive group-lasso penalty term on cluster centers. in order to optimally balance the tradeoff between the cluster fitting and sparsity, a tuning criterion based on clustering stability is developed. in theory, we provide an unbiased estimator for the degrees of freedom of the proposed sparse convex clustering method. finally, the effectiveness of the sparse convex clustering is examined through a variety of numerical experiments and a real data application.",10.1080/10618600.2017.1377081,1/18/2016,2/10/2017,"['wang', 'zhang', 'sun', 'fang']","['cs', 'stat']"
88,83,1511.08904,modeling and analysis of information communities,"['cs.si', 'cs.gt']","communities are an important feature of social networks. in fact, it seems that communities are necessary for a social network to be efficient. however, there exist very few formal studies of the actual role of communities in social networks, how they emerge, and how they are structured. the goal of this paper is to propose a mathematical model to study communities in social networks. for this, we consider a particular case of a social network, namely information networks. we assume that there is a population of agents who are interested in obtaining content. agents differ in the type of content they are interested in. the goal of agents is to form communities in order to maximize their utility for obtaining and producing content. we use this model to characterize the structure of communities that emerge in this setting. while the proposed model is very simple, the obtained results suggest that it indeed is able to capture key properties of information communities.",,11/28/2015,1/31/2019,['marbach'],['cs']
89,62,1506.02703,quasi-concavity for gaussian multicast relay channels,"['cs.it', 'math.it']","standard upper and lower bounds on the capacity of relay channels are cut-set (cs), decode-forward (df), and quantize-forward (qf) rates. for real additive white gaussian noise (awgn) multicast relay channels with one source node and one relay node, these bounds are shown to be quasi-concave in the receiver signal-to-noise ratios and the squared source-relay correlation coefficient. furthermore, the cs rates are shown to be quasi-concave in the relay position for a fixed correlation coefficient, and the df rates are shown to be quasi-concave in the relay position. the latter property characterizes the optimal relay position when using df.",,6/8/2015,1/24/2019,"['thakur', 'kramer']","['cs', 'math']"
90,74,1510.08174,visual quality enhancement in optoacoustic tomography using active   contour segmentation priors,"['physics.med-ph', 'cs.cv', 'eess.iv', 'physics.optics']","segmentation of biomedical images is essential for studying and characterizing anatomical structures, detection and evaluation of pathological tissues. segmentation has been further shown to enhance the reconstruction performance in many tomographic imaging modalities by accounting for heterogeneities of the excitation field and tissue properties in the imaged region. this is particularly relevant in optoacoustic tomography, where discontinuities in the optical and acoustic tissue properties, if not properly accounted for, may result in deterioration of the imaging performance. efficient segmentation of optoacoustic images is often hampered by the relatively low intrinsic contrast of large anatomical structures, which is further impaired by the limited angular coverage of some commonly employed tomographic imaging configurations. herein, we analyze the performance of active contour models for boundary segmentation in cross-sectional optoacoustic tomography. the segmented mask is employed to construct a two compartment model for the acoustic and optical parameters of the imaged tissues, which is subsequently used to improve accuracy of the image reconstruction routines. the performance of the suggested segmentation and modeling approach are showcased in tissue-mimicking phantoms and small animal imaging experiments.",10.1109/tmi.2016.2553156,10/27/2015,4/10/2016,"['mandal', 'deán-ben', 'razansky']","['cs', 'eess', 'physics']"
91,45,1412.8461,from clarity to efficiency for distributed algorithms,"['cs.pl', 'cs.dc']","this article describes a very high-level language for clear description of distributed algorithms and optimizations necessary for generating efficient implementations. the language supports high-level control flows where complex synchronization conditions can be expressed using high-level queries, especially logic quantifications, over message history sequences. unfortunately, the programs would be extremely inefficient, including consuming unbounded memory, if executed straightforwardly.   we present new optimizations that automatically transform complex synchronization conditions into incremental updates of necessary auxiliary values as messages are sent and received. the core of the optimizations is the first general method for efficient implementation of logic quantifications. we have developed an operational semantics of the language, implemented a prototype of the compiler and the optimizations, and successfully used the language and implementation on a variety of important distributed algorithms.",10.1145/2994595,12/29/2014,3/11/2017,"['liu', 'stoller', 'lin']",['cs']
92,40,1411.4,how to scale up kernel methods to be as good as deep neural nets,"['cs.lg', 'cs.ai', 'stat.ml']","the computational complexity of kernel methods has often been a major barrier for applying them to large-scale learning problems. we argue that this barrier can be effectively overcome. in particular, we develop methods to scale up kernel models to successfully tackle large-scale learning problems that are so far only approachable by deep learning architectures. based on the seminal work by rahimi and recht on approximating kernel functions with features derived from random projections, we advance the state-of-the-art by proposing methods that can efficiently train models with hundreds of millions of parameters, and learn optimal representations from multiple kernels. we conduct extensive empirical studies on problems from image recognition and automatic speech recognition, and show that the performance of our kernel models matches that of well-engineered deep neural nets (dnns). to the best of our knowledge, this is the first time that a direct comparison between these two methods on large-scale problems is reported. our kernel methods have several appealing properties: training with convex optimization, cost for training a single model comparable to dnns, and significantly reduced total cost due to fewer hyperparameters to tune for model selection. our contrastive study between these two very different but equally competitive models sheds light on fundamental questions such as how to learn good representations.",,11/14/2014,6/17/2015,"['lu', 'may', 'liu', 'garakani', 'guo', 'bellet', 'fan', 'collins', 'kingsbury', 'picheny', 'sha']","['cs', 'stat']"
93,78,1511.0294199999998,extrapush for convex smooth decentralized optimization over directed   networks,"['math.oc', 'cs.dc', 'cs.ro']","in this note, we extend the algorithms extra and subgradient-push to a new algorithm extrapush for consensus optimization with convex differentiable objective functions over a directed network. when the stationary distribution of the network can be computed in advance}, we propose a simplified algorithm called normalized extrapush. just like extra, both extrapush and normalized extrapush can iterate with a fixed step size. but unlike extra, they can take a column-stochastic mixing matrix, which is not necessarily doubly stochastic. therefore, they remove the undirected-network restriction of extra. subgradient-push, while also works for directed networks, is slower on the same type of problem because it must use a sequence of diminishing step sizes.   we present preliminary analysis for extrapush under a bounded sequence assumption. for normalized extrapush, we show that it naturally produces a bounded, linearly convergent sequence provided that the objective function is strongly convex.   in our numerical experiments, extrapush and normalized extrapush performed similarly well. they are significantly faster than subgradient-push, even when we hand-optimize the step sizes for the latter.",10.4208/jcm.1606-m2015-0452,11/9/2015,1/29/2019,"['zeng', 'yin']","['cs', 'math']"
94,3,808.2246,comparing human and automatic thesaurus mapping approaches in the   agricultural domain,['cs.dl'],"knowledge organization systems (kos), like thesauri and other controlled vocabularies, are used to provide subject access to information systems across the web. due to the heterogeneity of these systems, mapping between vocabularies becomes crucial for retrieving relevant information. however, mapping thesauri is a laborious task, and thus big efforts are being made to automate the mapping process. this paper examines two mapping approaches involving the agricultural thesaurus agrovoc, one machine-created and one human created. we are addressing the basic question ""what are the pros and cons of human and automatic mapping and how can they complement each other?"" by pointing out the difficulties in specific cases or groups of cases and grouping the sample into simple and difficult types of mappings, we show the limitations of current automatic methods and come up with some basic recommendations on what approach to use when.",10.18452/1251,8/16/2008,,"['lauser', 'johannsen', 'caracciolo', 'keizer', 'van hage', 'mayr']",['cs']
95,21,1309.7666,dynamic sliding mode control based on fractional calculus subject to   uncertain delay based chaotic pneumatic robot,"['cs.ro', 'cs.sy']","this paper considers the chattering problem of sliding mode control while delay in robot manipulator caused chaos in such electromechanical systems. fractional calculus as a powerful theorem to produce a novel sliding mode; which has a dynamic essence is used for chattering elimination. to realize the control of a class of chaotic systems in master-slave configuration this novel fractional dynamic sliding mode control scheme is presented and examined on delay based chaotic robot in joint and work space. also the stability of the closed-loop system is guaranteed by lyapunov stability theory. beside these, delayed robot motions are sorted out for qualitative and quantification study. finally, numerical simulation example illustrates the feasibility of proposed control method.",,9/29/2013,1/15/2019,"['p.', 'shandiz', 'alizadeh', 'minagar', 'kazemitabar']",['cs']
96,67,1507.06268,a discrete log-sobolev inequality under a bakry-emery type condition,"['math.pr', 'cs.it', 'math.it']","we consider probability mass functions $v$ supported on the positive integers using arguments introduced by caputo, dai pra and posta, based on a bakry--\'{e}mery condition for a markov birth and death operator with invariant measure $v$. under this condition, we prove a modified logarithmic sobolev inequality, generalizing and strengthening results of wu, bobkov and ledoux, and caputo, dai pra and posta. we show how this inequality implies results including concentration of measure and hypercontractivity, and discuss how it may extend to higher dimensions.",10.1214/16-aihp778,7/22/2015,7/6/2016,['johnson'],"['cs', 'math']"
97,56,1504.0814599999999,regular graphs are antimagic,"['cs.dm', 'math.co']","an undirected simple graph $g=(v,e)$ is called antimagic if there exists an injective function $f:e\rightarrow\{1,\dots,|e|\}$ such that $\sum_{e\in e(u)} f(e)\neq\sum_{e\in e(v)} f(e)$ for any pair of different nodes $u,v\in v$. in a previous version of the paper, the authors gave a proof that regular graphs are antimagic. however, the proof of the main theorem is incorrect as one of the steps uses an invalid assumption. the aim of the present erratum is to fix the proof.",,4/30/2015,1/9/2019,"['bérczi', 'bernáth', 'vizer']","['cs', 'math']"
98,89,1602.04584,weyl spreading sequence optimizing cdma,"['cs.it', 'math.it', 'nlin.cd']","this paper shows an optimal spreading sequence in the weyl sequence class, which is similar to the set of the oppermann sequences for asynchronous cdma systems. sequences in weyl sequence class have the desired property that the order of cross-correlation is low. therefore, sequences in the weyl sequence class are expected to minimize the inter-symbol interference. we evaluate the upper bound of cross-correlation and odd cross-correlation of spreading sequences in the weyl sequence class and construct the optimization problem: minimize the upper bound of the absolute values of cross-correlation and odd cross-correlation. since our optimization problem is convex, we can derive the optimal spreading sequences as the global solution of the problem. we show their signal to interference plus noise ratio (sinr) in a special case. from this result, we propose how the initial elements are assigned, that is, how spreading sequences are assigned to each users. in an asynchronous cdma system, we also numerically compare our spreading sequences with other ones, the gold codes, the oppermann sequences, the optimal chebyshev spreading sequences and the sp sequences in bit error rate. our spreading sequence, which yields the global solution, has the highest performance among the other spreading sequences tested.",,2/15/2016,1/18/2019,"['tsuda', 'umeno']","['cs', 'physics', 'math']"
99,95,1604.00359,using well-understood single-objective functions in multiobjective   black-box optimization test suites,"['cs.ai', 'cs.na', 'cs.ne']","several test function suites are being used for numerical benchmarking of multiobjective optimization algorithms. while they have some desirable properties, like well-understood pareto sets and pareto fronts of various shapes, most of the currently used functions possess characteristics that are arguably under-represented in real-world problems. they mainly stem from the easier construction of such functions and result in improbable properties such as separability, optima located exactly at the boundary constraints, and the existence of variables that solely control the distance between a solution and the pareto front. here, we propose an alternative way to constructing multiobjective problems-by combining existing single-objective problems from the literature. we describe in particular the bbob-biobj test suite with 55 bi-objective functions in continuous domain, and its extended version with 92 bi-objective functions (bbob-biobj-ext). both test suites have been implemented in the coco platform for black-box optimization benchmarking. finally, we recommend a general procedure for creating test suites for an arbitrary number of objectives. besides providing the formal function definitions and presenting their (known) properties, this paper also aims at giving the rationale behind our approach in terms of groups of functions with similar properties, objective space normalization, and problem instances. the latter allows us to easily compare the performance of deterministic and stochastic solvers, which is an often overlooked issue in benchmarking.",,4/1/2016,1/4/2019,"['brockhoff', 'tusar', 'auger', 'hansen']",['cs']
